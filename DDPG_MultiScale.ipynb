{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_list = ['MMM', 'T', 'ABBV', 'ABT', 'ACN', 'AGN', 'ALL', 'GOOGL', \n",
    "              'GOOG', 'MO', 'AMZN', 'AXP', 'AIG', 'AMGN', 'AAPL', 'BAC', 'BIIB', \n",
    "              'BLK', 'BA', 'BMY', 'CVS', 'COF', 'CAT', 'CELG', 'CVX', 'CSCO', 'C', \n",
    "              'KO', 'CL', 'CMCSA', 'COP', 'COST', 'DHR', 'DOW', 'DUK', 'DD', 'EMC', \n",
    "              'EMR', 'EXC', 'XOM', 'FB', 'FDX', 'F', 'GD', 'GE', 'GM', 'GILD', 'GS', 'HAL', \n",
    "              'HD', 'HON', 'INTC', 'IBM', 'JPM', 'JNJ', 'KMI', 'LLY', 'LMT', 'LOW', 'MA', \n",
    "              'MCD', 'MDT', 'MRK', 'MET', 'MSFT', 'MDLZ', 'MON', 'MS', 'NKE', 'OXY', \n",
    "              'ORCL', 'PEP', 'PFE', 'PM', 'PG', 'QCOM', 'RTN', 'SLB', 'SPG', 'SO', 'SBUX', \n",
    "              'TGT', 'TXN', 'BK', 'PCLN', 'TWX', 'FOXA', 'FOX', 'USB', 'UNP', 'UPS', 'UTX', \n",
    "              'UNH', 'VZ', 'V', 'WMT', 'WBA', 'DIS', 'WFC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!!\n",
      "('fail_name_list: ', [])\n",
      "time for getting data: 71.0388810635\n"
     ]
    }
   ],
   "source": [
    "print (\"Started!!\")\n",
    "\n",
    "st = time.time()\n",
    "start_date=\"2011-04-01\"\n",
    "end_date=\"2016-04-01\"\n",
    "input_data, input_list = utils.get_fixed_data(input_list[:10], start_date=start_date, end_date=end_date) \n",
    "elapsed = time.time() - st\n",
    "print (\"time for getting data:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_value = input_data.values\n",
    "index = input_data.index\n",
    "input_tilde = pd.DataFrame(input_value[:, :10], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2517, 9)\n"
     ]
    }
   ],
   "source": [
    "print (input_tilde.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2011-04-01', '2011-04-04', '2011-04-05', '2011-04-06',\n",
      "               '2011-04-07', '2011-04-08', '2011-04-11', '2011-04-12',\n",
      "               '2011-04-13', '2011-04-14',\n",
      "               ...\n",
      "               '2016-03-18', '2016-03-21', '2016-03-22', '2016-03-23',\n",
      "               '2016-03-24', '2016-03-28', '2016-03-29', '2016-03-30',\n",
      "               '2016-03-31', '2016-04-01'],\n",
      "              dtype='datetime64[ns]', length=1258, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(input_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG for trading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data, you are going to learn how to manage your portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "index = pd.date_range('23/10/2016', periods=100, freq='D')\n",
    "value = np.random.normal(0, 1, (len(index), n_stock))\n",
    "input_tilde = pd.DataFrame(value, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.power??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "Experiecne = namedtuple('Experience', 'state0,  action, reward, state1')\n",
    "\n",
    "class RingBuffer(object):\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.start = 0\n",
    "        self.length = 0\n",
    "        # self.data = [None for _ in range(maxlen)]\n",
    "        self.data = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx< 0 or idx >= self.length:\n",
    "            raise KeyError()\n",
    "        return self.data[(self.start + idx) % self.maxlen]\n",
    "    \n",
    "    def append(self, v):\n",
    "        if self.length < self.maxlen:\n",
    "            # We have space, simply increase the length\n",
    "            self.length += 1\n",
    "        elif self.length == self.maxlen:\n",
    "            # No space, \"remove\" the first item\n",
    "            self.data[:-1] = self.data[1:]\n",
    "        else:\n",
    "            # This should never happen\n",
    "            raise RuntimeError()\n",
    "        self.data.append(v)\n",
    "        \n",
    "class SequentialMemory(object):\n",
    "    def __init__(self, limit=1000):\n",
    "        self.limit = limit\n",
    "        self.priority = []\n",
    "        self.actions = RingBuffer(limit)\n",
    "        self.rewards = RingBuffer(limit)\n",
    "        self.observations = RingBuffer(limit)\n",
    "        self.batch_idx = None\n",
    "        \n",
    "    def sample(self, batch_size, window_length, alpha=1.0, beta=1.0, epsilon=0.05):\n",
    "        # udpate priority when sampling\n",
    "        if len(self.priority) > self.limit:\n",
    "            self.priority = self.priority[-self.limit:]\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        index_space = np.arange(window_length, self.nb_entries)\n",
    "        # prioritized sample\n",
    "        p = np.array(self.priority)[window_length:]\n",
    "        p_tilde = p + np.ones(self.nb_entries - window_length) * np.mean(p) * epsilon\n",
    "        p_tilde[-1] = np.mean(p)\n",
    "        p_tilde = p_tilde ** alpha\n",
    "        p_tilde = p_tilde / np.sum(p_tilde)\n",
    "        batch_idx = choice(index_space, p=p_tilde, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries - 1]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        # keep batch_idx to update pritority\n",
    "        self.batch_idx = batch_idx\n",
    "        \n",
    "        # weights to modify biased update\n",
    "        weights = 1. / (p_tilde**beta)\n",
    "        weights = weights / np.max(weights)\n",
    "        ret_w = weights[batch_idx - window_length]\n",
    "        \n",
    "        # create experiences\n",
    "        state0 = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        action = np.array([self.actions[idx - 1] for idx in batch_idx])\n",
    "        reward = np.array([self.rewards[idx - 1] for idx in batch_idx])\n",
    "        state1 = np.array([[self.observations[i] for i in range(idx - window_length + 1,idx + 1)] for idx in batch_idx])\n",
    "        return Experiecne(state0, action, reward, state1), ret_w\n",
    "    \n",
    "    def sample_state(self, batch_size, window_length, alpha=0.5, epsilon=0.05):\n",
    "        # udpate priority when sampling\n",
    "        if len(self.priority) > self.limit:\n",
    "            self.priority = self.priority[-self.limit:]\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        index_space = np.arange(window_length, self.nb_entries)\n",
    "        # prioritized sample\n",
    "        p = np.array(self.priority)[window_length:]\n",
    "        p_tilde = p + np.ones(self.nb_entries - window_length) * np.mean(p) * epsilon\n",
    "        p_tilde[-1] = np.mean(p)\n",
    "        p_tilde = p_tilde ** alpha\n",
    "        p_tilde = p_tilde / np.sum(p_tilde)\n",
    "        batch_idx = choice(index_space, p=p_tilde, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def update_priority(self,error):\n",
    "        for idx, i in enumerate(self.batch_idx):\n",
    "            self.priority[i] = error[idx]\n",
    "    \n",
    "    \n",
    "    def append(self, observation, action, reward):\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        # initialize new sample with 1\n",
    "        self.priority.append(1.0)\n",
    "    \n",
    "    @property\n",
    "    def nb_entries(self):\n",
    "        return  len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# from memory import SequentialMemory\n",
    "\n",
    "class DDPG(object):\n",
    "    \"\"\"Deep Deterministic Poilicy Gradient\n",
    "    \n",
    "    Basend on DPG and Multiscale CNN, seek out \n",
    "    optimal strategy for stock trading.\n",
    "    \n",
    "    Available function\n",
    "    - build_model: build network basedon tensorflow and keras\n",
    "    - train: given DateFrame stock data, train network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        config should have the following attributes\n",
    "        \n",
    "        Args:\n",
    "            gamma(float): the decay rate for value at RL\n",
    "            history_length(int): input_length for each scale at CNN\n",
    "            n_feature(int): the number of type of input \n",
    "                (e.g. the number of company to use at stock trading)\n",
    "            trade_stock_idx(int): trading stock index\n",
    "            gam (float): discount factor\n",
    "            n_history(int): the nubmer of history that will be used as input\n",
    "            n_smooth, n_down(int): the number of smoothed and down sampling input at CNN\n",
    "            k_w(int): the size of filter at CNN\n",
    "            n_hidden(int): the size of fully connected layer\n",
    "            n_batch(int): the size of mini batch\n",
    "            n_epochs(int): the training epoch for each time\n",
    "            update_rate (0, 1): parameter for soft update\n",
    "            learning_rate(float): learning rate for SGD\n",
    "        \"\"\"\n",
    "        self.device = config.device\n",
    "        self.save_path = config.save_path\n",
    "        self.is_load = config.is_load\n",
    "        self.gamma = config.gamma\n",
    "        self.history_length = config.history_length\n",
    "        self.n_stock = config.n_stock\n",
    "        self.n_feature = config.n_feature\n",
    "        self.n_smooth = config.n_smooth\n",
    "        self.n_down = config.n_down\n",
    "        self.k_w = config.k_w\n",
    "        self.n_hidden = config.n_hidden\n",
    "        self.n_batch = config.n_batch\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.update_rate = config.update_rate\n",
    "        self.alpha = config.alpha\n",
    "        self.beta = config.beta\n",
    "        self.lr = config.learning_rate\n",
    "        # the actual dimention of input\n",
    "        # self.n_input = (1 + self.n_smooth + self.n_down) * self.n_stock\n",
    "        # the length of the data as input\n",
    "        self.n_history = max(self.n_smooth + self.history_length, (self.n_down + 1) * self.history_length)\n",
    "        print (\"building model....\")\n",
    "        # have compatibility with new tensorflow\n",
    "        tf.python.control_flow_ops = tf\n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "        # self.sess = tf.Session()\n",
    "        K.set_session(self.sess)\n",
    "        with self.sess.as_default():\n",
    "            with tf.device(self.device):\n",
    "                self.build_model()\n",
    "        print('finished building model!')\n",
    "    \n",
    "    def train(self, input_data, n_memory=1000, noise_scale=0.3):\n",
    "        \"\"\"training DDPG, where action is confined to integer space\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): stock price for self.n_feature companies\n",
    "        \"\"\"\n",
    "        stock_data = input_data.values\n",
    "        date = input_data.index\n",
    "        T = len(stock_data)\n",
    "        \n",
    "        # frequency for output\n",
    "        print_freq = int(T / 100)\n",
    "        if print_freq == 0:\n",
    "            print_freq = 1\n",
    "            \n",
    "        print_freq = 1\n",
    "            \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        # prioritizomg parameter\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        db = (1 - beta) / 1000\n",
    "        \n",
    "        # result for return value\n",
    "        values = []\n",
    "        date_label = []\n",
    "        value = 0\n",
    "        values.append(value)\n",
    "        date_label.append(date[0])\n",
    "        # keep half an year data \n",
    "        memory = SequentialMemory(n_memory)\n",
    "        plot_freq = 10\n",
    "        save_freq = 10\n",
    "        count = 0\n",
    "        for t in range(T - 1):\n",
    "            # until having enough data, just do nothing\n",
    "            if t <= self.n_history + self.n_batch:\n",
    "                # action_off = np.round(np.random.normal(0, noise_scale, self.n_stock))\n",
    "                action_off = np.random.normal(0, 10, self.n_stock)\n",
    "                reward = np.sum((stock_data[t + 1] - stock_data[t]) * action_off)\n",
    "                memory.append(stock_data[t], action_off, reward)\n",
    "                continue\n",
    "            price = stock_data[t]\n",
    "            future_price = stock_data[t + 1]\n",
    "            memory.observations.append(price)\n",
    "            memory.priority.append(1.0)\n",
    "            # to stabilize batch normalization, use other samples for prediction\n",
    "            pred_state = memory.sample_state(self.n_batch, self.n_history)\n",
    "            # off policy action and update portfolio\n",
    "            actor_action = self.actor_output.eval(session=self.sess,\n",
    "                                      feed_dict={self.state: pred_state,\n",
    "                                                          K.learning_phase(): 0})[-1]\n",
    "            # action_off = np.round(actor_value_off + np.random.normal(0, noise_scale, self.n_stock))\n",
    "            var = np.mean(actor_action ** 2)\n",
    "            action_off = actor_action + np.random.normal(0, np.sqrt(var) * noise_scale, self.n_stock)\n",
    "            # action_off = actor_value_off\n",
    "            reward_off = reward = np.sum((future_price - price) * action_off)\n",
    "            memory.rewards.append(reward_off)\n",
    "            memory.actions.append(action_off)\n",
    "            # on policy action and update portfolio\n",
    "            # action_on = np.round(actor_value_on)\n",
    "            action_on = actor_action\n",
    "            reward_on = np.sum((future_price - price) * action_on)\n",
    "            value += reward_on\n",
    "            date_label.append(date[t+1])\n",
    "            values.append(value)\n",
    "            experiences_test = memory.sample(self.n_batch, self.n_history)\n",
    "            # update network\n",
    "            critic_value = self.sess.run(self.Q_actor,\n",
    "                                      feed_dict={self.state: pred_state,\n",
    "                                                K.learning_phase(): 0})[-1]\n",
    "            count += 1\n",
    "            for epoch in range(self.n_epochs):    \n",
    "                # select transition from pool\n",
    "                experiences, weights = memory.sample(self.n_batch, self.n_history, alpha, beta)\n",
    "                self.sess.run(self.critic_optim, \n",
    "                              feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         self.weights: weights,\n",
    "                                         self.learning_rate: self.lr,\n",
    "                                         K.learning_phase(): 1})  \n",
    "                self.sess.run(self.actor_optim,\n",
    "                                       feed_dict={self.state: experiences.state0,\n",
    "                                                            self.learning_rate: self.lr,\n",
    "                                                            K.learning_phase(): 1})  \n",
    "                \n",
    "                error = self.sess.run(self.error,\n",
    "                                      feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         K.learning_phase(): 0})\n",
    "                memory.update_priority(error)\n",
    "                \n",
    "                loss = self.sess.run(self.loss, feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         self.weights: weights,\n",
    "                                         K.learning_phase(): 1})\n",
    "                \n",
    "                target_value = self.sess.run(self.target_value, feed_dict={\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         K.learning_phase(): 1})\n",
    "                # print('critic_value', critic_value)\n",
    "                \n",
    "                \n",
    "                # print('target:', np.mean(target_value))\n",
    "                # print('Q_value:', np.mean(target_value - experiences.reward))\n",
    "                # print('reward:', np.mean(experiences.reward))\n",
    "                    \n",
    "                # softupdate for critic network\n",
    "                old_weights = self.critic_target.get_weights()\n",
    "                new_weights = self.critic.get_weights()\n",
    "                weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w for new_w, old_w in zip(new_weights, old_weights)]\n",
    "                self.critic_target.set_weights(weights)\n",
    "                \n",
    "                # softupdate for actor network\n",
    "                old_weights = self.actor_target.get_weights()\n",
    "                new_weights = self.actor.get_weights()\n",
    "                weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w for new_w, old_w in zip(new_weights, old_weights)]\n",
    "                self.actor_target.set_weights(weights)\n",
    "                \n",
    "                # update prioritizing paramter untill it goes over 1\n",
    "                beta  += db\n",
    "                if beta >= 1.0:\n",
    "                    beta = 1.0\n",
    "                 \n",
    "            if t % print_freq == 0:\n",
    "                print (\"time:\",  date[t + 1])\n",
    "                print(\"reward:\", reward_on)\n",
    "                print('critic_value', critic_value)\n",
    "                print(\"value:\", value)\n",
    "                print(\"portfolio:\", action_on)\n",
    "                # print('batch_idx:', memory.batch_idx)\n",
    "                print('priority:', np.mean(memory.priority))\n",
    "                # print('loss:', loss)\n",
    "                print (\"elapsed time\", time.time() - st)\n",
    "                print(\"********************************************************************\")\n",
    "                \n",
    "            if count % plot_freq == 0:\n",
    "                result = pd.DataFrame(values, index=pd.DatetimeIndex(date_label))\n",
    "                result.to_csv(\"trading_result_{}.csv\".format(date[t + 1]))\n",
    "                # plt.plot(result)\n",
    "                \n",
    "            if count % save_freq == 0:\n",
    "                save_path = self.saver.save(self.sess, self.save_path)\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        print (\"finished training\")\n",
    "           \n",
    "        return pd.DataFrame(values, index=pd.DatetimeIndex(date_label))\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build all of the network and optimizations\n",
    "        \n",
    "        just for conveninece of trainig, seprate placehoder for train and target network\n",
    "        critic network input: [raw_data, smoothed, downsampled, action]\n",
    "        actor network input: [raw_data, smoothed, downsampled]\n",
    "        \"\"\"\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic_target = self.build_critic()\n",
    "        # actor network input should be [raw_data, smoothed, downsampled]\n",
    "        self.actor = self.build_actor()\n",
    "        self.actor_target = self.build_actor()\n",
    "        # transform input into the several scales and smoothing\n",
    "        self.state =  tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state')\n",
    "        self.state_target = tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state_target')\n",
    "        # reshape to convolutional input\n",
    "        state_ = tf.reshape(self.state, [-1, self.n_history, self.n_stock, 1])\n",
    "        state_target_ = tf.reshape(self.state_target, [-1, self.n_history, self.n_stock, 1])\n",
    "        raw, smoothed, down = self.transform_input(state_)\n",
    "        raw_target, smoothed_target, down_target = self.transform_input(state_target_)\n",
    "        \n",
    "        # build graph for citic training\n",
    "        self.action = tf.placeholder(tf.float32, [None, self.n_stock])\n",
    "        input_q = [raw,] +  smoothed + down + [self.action,]\n",
    "        self.Q = tf.squeeze(self.critic(input_q))\n",
    "        # target network\n",
    "        self.actor_target_output = self.actor_target([raw_target,] +  smoothed_target + down_target)\n",
    "        input_q_target = [raw_target,] +  smoothed_target + down_target + [self.actor_target_output,]\n",
    "        Q_target = tf.squeeze(self.critic_target(input_q_target))\n",
    "        self.reward = tf.placeholder(tf.float32, [None], name='reward')\n",
    "        target = self.reward  + self.gamma * Q_target\n",
    "        self.target_value = self.reward  + self.gamma * Q_target\n",
    "        # optimization\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        # get rid of bias of prioritized\n",
    "        self.weights = tf.placeholder(tf.float32, shape=[None], name=\"weights\")\n",
    "        self.loss = tf.reduce_mean(self.weights * tf.square(target - self.Q), name='loss')\n",
    "        # TD-error for priority\n",
    "        self.error = tf.abs(target - self.Q)\n",
    "        self.critic_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(self.loss, var_list=self.critic.trainable_weights)\n",
    "        \n",
    "        # build graph for actor training\n",
    "        self.actor_output = self.actor([raw,] +  smoothed + down)\n",
    "        input_q_actor = [raw,] +  smoothed + down + [self.actor_output,]\n",
    "        self.Q_actor = tf.squeeze(self.critic(input_q_actor))\n",
    "        # optimization\n",
    "        self.actor_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(-self.Q_actor, var_list=self.actor.trainable_weights)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        is_initialize = True\n",
    "        if self.is_load:\n",
    "            if self.load(self.save_path):\n",
    "                print('succeded to load')\n",
    "                is_initialize = False\n",
    "            else:\n",
    "                print('failed to load')\n",
    "        \n",
    "        # initialize network\n",
    "        if is_initialize:\n",
    "            tf.initialize_all_variables().run(session=self.sess)\n",
    "            weights = self.critic.get_weights()\n",
    "            self.critic_target.set_weights(weights)\n",
    "            weights = self.actor.get_weights()\n",
    "            self.actor_target.set_weights(weights)\n",
    "        \n",
    "    def build_critic(self):\n",
    "        \"\"\"Build critic network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        nf = self.n_feature\n",
    "        # layer1\n",
    "        # smoothed input\n",
    "        sm_model = [Sequential() for _ in range(self.n_smooth)]\n",
    "        for m in sm_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # down sampled input\n",
    "        dw_model = [Sequential() for _ in range(self.n_down)]\n",
    "        for m in dw_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # raw input\n",
    "        state = Sequential()\n",
    "        nf = self.n_feature\n",
    "        state.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "        # state.add(SpatialDropout2D(0.2))\n",
    "        state.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        state.add(BatchNormalization(mode=2, axis=-1))\n",
    "        state.add(PReLU())\n",
    "        merged = Merge([state,] + sm_model + dw_model, mode='concat', concat_axis=-1)\n",
    "        # layer2\n",
    "        nf = nf * 2\n",
    "        merged_state = Sequential()\n",
    "        merged_state.add(merged)\n",
    "        # merged_state.add(SpatialDropout2D(0.2))\n",
    "        merged_state.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        merged_state.add(BatchNormalization(mode=2, axis=-1))\n",
    "        merged_state.add(PReLU())\n",
    "        merged_state.add(Flatten())\n",
    "        # layer3\n",
    "        action = Sequential()\n",
    "        action.add(Lambda(lambda x: x, input_shape=(self.n_stock,)))\n",
    "        action.add(BatchNormalization(mode=1, axis=-1))\n",
    "        merged = Merge([merged_state, action], mode='concat')\n",
    "        model = Sequential()\n",
    "        model.add(merged)\n",
    "        model.add(Dense(self.n_hidden))\n",
    "        model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # layer4\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(int(np.sqrt(self.n_hidden))))\n",
    "        model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # output\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        return model\n",
    "    \n",
    "    def build_actor(self):\n",
    "        \"\"\"Build actor network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        nf = self.n_feature\n",
    "        # layer1\n",
    "        # smoothed input\n",
    "        sm_model = [Sequential() for _ in range(self.n_smooth)]\n",
    "        for m in sm_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # down sampled input\n",
    "        dw_model = [Sequential() for _ in range(self.n_down )]\n",
    "        for m in dw_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # raw input     \n",
    "        state = Sequential()\n",
    "        state.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "        # state.add(SpatialDropout2D(0.2))\n",
    "        state.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        state.add(BatchNormalization(mode=2, axis=-1))\n",
    "        state.add(PReLU())\n",
    "        merged = Merge([state,] + sm_model + dw_model, mode='concat')\n",
    "        # layer2\n",
    "        nf = nf * 2\n",
    "        model = Sequential()\n",
    "        model.add(merged)\n",
    "        model.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        model.add(BatchNormalization(mode=2 , axis=-1))\n",
    "        model.add(PReLU())\n",
    "        model.add(Flatten())\n",
    "        # layer3\n",
    "        model.add(Dense(self.n_hidden))\n",
    "        # model.add(BatchNormalization(mode=1, axis=-1))}\n",
    "        model.add(PReLU())\n",
    "        # output\n",
    "        model.add(Dense(self.n_stock))\n",
    "        return model\n",
    "    \n",
    "    def transform_input(self, input):\n",
    "        # the last data is the newest information\n",
    "        raw = input[:, self.n_history - self.history_length:, :, :]\n",
    "        # smooth data\n",
    "        smoothed = []\n",
    "        for n_sm in range(2, self.n_smooth + 2):\n",
    "            smoothed.append(\n",
    "                tf.reduce_mean(tf.pack([input[:, self.n_history - st - self.history_length:self.n_history - st, :, :] for st in range(n_sm)]),0)\n",
    "            )\n",
    "        # downsample data\n",
    "        down = []\n",
    "        for n_dw in range(2, self.n_down + 2):\n",
    "            sampled_ = tf.pack([input[:, idx, :, :] for idx in range(self.n_history-n_dw*self.history_length, self.n_history, n_dw)])\n",
    "            down.append(tf.transpose(sampled_, [1, 0, 2, 3]))\n",
    "        return raw, smoothed, down\n",
    "    \n",
    "    def load(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        try:\n",
    "            self.saver.restore(self.sess, self.save_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "n_stock = len(input_tilde.values[0])\n",
    "# n_stock = 10\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    device = '/gpu:0'\n",
    "    save_path = '/home/tomoaki/work/github/DQN/DDPG_model.ckpt'\n",
    "    is_load = False\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 10\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 100\n",
    "    n_feature = 32\n",
    "    alpha = 0.7\n",
    "    beta = 0.5\n",
    "    update_rate = 1e-2\n",
    "    learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n"
     ]
    }
   ],
   "source": [
    "# from model import DDPG\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = MultiDDPGConfig()\n",
    "\n",
    "dqn = DDPG(config)\n",
    "print (\"start!\")\n",
    "values = dqn.train(input_tilde)\n",
    "print (\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(values)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('profit')\n",
    "plt.savefig('DDPG_trading.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values.to_csv(\"trading_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"trading_result.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f63cd593dd0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEDCAYAAAAiKuN6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARBECwhwiEIgiBYQoRDEARBsMT/Bw8wwlTkbr8ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63cd64ad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DatetimeIndex(data.index), data.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'2006-04-03', u'2006-08-16', u'2006-08-17', u'2006-08-18',\n",
       "       u'2006-08-21', u'2006-08-22', u'2006-08-23', u'2006-08-24',\n",
       "       u'2006-08-25', u'2006-08-28',\n",
       "       ...\n",
       "       u'2016-03-18', u'2016-03-21', u'2016-03-22', u'2016-03-23',\n",
       "       u'2016-03-24', u'2016-03-28', u'2016-03-29', u'2016-03-30',\n",
       "       u'2016-03-31', u'2016-04-01'],\n",
       "      dtype='object', length=2424)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 2, 3]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(([[1, 2]], [[2, 3]]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01               inf  0.0625      1.                 inf  0.0625\n",
      "  0.02040816  0.0625      0.25        1.        ]\n",
      "[10  0  4  1  0  4  7  4  2  1]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.random_integers(0, 10, 10)\n",
    "print(1./a ** (2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9,  8,  1,  1,  6,  4,  9, 10,  9])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
