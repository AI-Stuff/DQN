{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!!\n",
      "time for getting data: 3.22771406174\n"
     ]
    }
   ],
   "source": [
    "print (\"Started!!\")\n",
    "\n",
    "st = time.time()\n",
    "symbols = utils.get_sap_symbols('sap500')\n",
    "np.random.shuffle(symbols)\n",
    "chosen_symbols = symbols[:1]\n",
    "start_date=\"2006-10-01\"\n",
    "end_date=\"2016-10-01\"\n",
    "# use Open data\n",
    "input_data = utils.get_data_list_key(chosen_symbols, start_date, end_date)\n",
    "elapsed = time.time() - st\n",
    "print (\"time for getting data:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_st = pd.Timestamp(\"2006-10-01\")\n",
    "train_end = pd.Timestamp(\"2015-10-01\")\n",
    "test_st = pd.Timestamp(\"2015-10-02\")\n",
    "test_end = pd.Timestamp(\"2016-10-01\")\n",
    "\n",
    "train_data = input_data.loc[(input_data.index >= train_st) & (input_data.index <= train_end)]\n",
    "test_data = input_data.loc[(input_data.index >= test_st) & (input_data.index <= test_end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG for trading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data, you are going to learn how to manage your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "# n_stock = len(input_tilde.values[0])\n",
    "n_stock = 10\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 6\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 10\n",
    "    n_feature = 32\n",
    "    update_rate = 1e-1\n",
    "    learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "index = pd.date_range('23/10/2016', periods=100, freq='D')\n",
    "value = np.random.normal(0, 1, (len(index), n_stock))\n",
    "input_data = pd.DataFrame(value, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "Experiecne = namedtuple('Experience', 'state0,  action, reward, state1')\n",
    "\n",
    "class RingBuffer(object):\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.start = 0\n",
    "        self.length = 0\n",
    "        # self.data = [None for _ in range(maxlen)]\n",
    "        self.data = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx< 0 or idx >= self.length:\n",
    "            raise KeyError()\n",
    "        return self.data[(self.start + idx) % self.maxlen]\n",
    "    \n",
    "    def append(self, v):\n",
    "        if self.length < self.maxlen:\n",
    "            # We have space, simply increase the length\n",
    "            self.length += 1\n",
    "        elif self.length == self.maxlen:\n",
    "            # No space, \"remove\" the first item\n",
    "            self.data[:-1] = self.data[1:]\n",
    "        else:\n",
    "            # This should never happen\n",
    "            raise RuntimeError()\n",
    "        self.data.append(v)\n",
    "        \n",
    "class SequentialMemory(object):\n",
    "    def __init__(self, limit=1000):\n",
    "        self.limit = limit\n",
    "        self.priority = []\n",
    "        self.actions = RingBuffer(limit)\n",
    "        self.rewards = RingBuffer(limit)\n",
    "        self.observations = RingBuffer(limit)\n",
    "        self.batch_idx = None\n",
    "        # print('priority:', self.priority)\n",
    "\n",
    "        \n",
    "    def sample(self, batch_size, window_length, alpha=1.0, beta=1.0, epsilon=0.05):\n",
    "        # udpate priority when sampling\n",
    "        if len(self.priority) > self.limit:\n",
    "            self.priority = self.priority[-self.limit:]\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        index_space = np.arange(window_length, self.nb_entries)\n",
    "        # prioritized sample\n",
    "        p = np.array(self.priority)[window_length:]\n",
    "        p_tilde = p + np.ones(self.nb_entries - window_length) * np.mean(p) * epsilon\n",
    "        p_tilde[-1] = np.mean(p)\n",
    "        p_tilde = p_tilde ** alpha\n",
    "        p_tilde = p_tilde / np.sum(p_tilde)\n",
    "        batch_idx = choice(index_space, p=p_tilde, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries - 1]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        # keep batch_idx to update pritority\n",
    "        self.batch_idx = batch_idx\n",
    "        \n",
    "        # weights to modify biased update\n",
    "        weights = 1. / (p_tilde**beta)\n",
    "        weights = weights / np.max(weights)\n",
    "        ret_w = weights[batch_idx - window_length]\n",
    "        \n",
    "        # create experiences\n",
    "        state0 = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        action = np.array([self.actions[idx - 1] for idx in batch_idx])\n",
    "        reward = np.array([self.rewards[idx - 1] for idx in batch_idx])\n",
    "        state1 = np.array([[self.observations[i] for i in range(idx - window_length + 1,idx + 1)] for idx in batch_idx])\n",
    "        return Experiecne(state0, action, reward, state1), ret_w\n",
    "    \n",
    "    def sample_state(self, batch_size, window_length, alpha=0.5, epsilon=0.05):\n",
    "        # udpate priority when sampling\n",
    "        if len(self.priority) > self.limit:\n",
    "            self.priority = self.priority[-self.limit:]\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        index_space = np.arange(window_length, self.nb_entries)\n",
    "        # prioritized sample\n",
    "        p = np.array(self.priority)[window_length:]\n",
    "        p_tilde = p + np.ones(self.nb_entries - window_length) * np.mean(p) * epsilon\n",
    "        p_tilde[-1] = np.mean(p)\n",
    "        p_tilde = p_tilde ** alpha\n",
    "        p_tilde = p_tilde / np.sum(p_tilde)\n",
    "        batch_idx = choice(index_space, p=p_tilde, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def sample_state_uniform(self, batch_size, window_length):\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        batch_idx = np.random.random_integers(window_length, self.nb_entries - 1, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length, idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def update_priority(self,error):\n",
    "        for idx, i in enumerate(self.batch_idx):\n",
    "            self.priority[i] = error[idx]\n",
    "    \n",
    "    \n",
    "    def append(self, observation, action, reward):\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        # initialize new sample with 1\n",
    "        self.priority.append(1.0)\n",
    "    \n",
    "    @property\n",
    "    def nb_entries(self):\n",
    "        return  len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# local library\n",
    "from memory import SequentialMemory\n",
    "\n",
    "class DQN(object):\n",
    "    \"\"\"Deep Deterministic Poilicy Gradient\n",
    "    \n",
    "    Basend on DDPG and Multiscale CNN, seek out \n",
    "    optimal strategy for stock trading.\n",
    "    \n",
    "    Available function\n",
    "    - build_model: build network based on tensorflow and keras\n",
    "    - train: given DateFrame stock data, train network\n",
    "    - predict_action: givne DataFrame stock data, return optimal protfolio\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        config should have the following attributes\n",
    "        \n",
    "        Args:\n",
    "            device: the device to use computation, e.g. '/gpu:0'\n",
    "            gamma(float): the decay rate for value at RL\n",
    "            history_length(int): input_length for each scale at CNN\n",
    "            n_feature(int): the number of type of input \n",
    "                (e.g. the number of company to use at stock trading)\n",
    "            trade_stock_idx(int): trading stock index\n",
    "            gam (float): discount factor\n",
    "            n_history(int): the nubmer of history that will be used as input\n",
    "            n_smooth, n_down(int): the number of smoothed and down sampling input at CNN\n",
    "            k_w(int): the size of filter at CNN\n",
    "            n_hidden(int): the size of fully connected layer\n",
    "            n_batch(int): the size of mini batch\n",
    "            n_epochs(int): the training epoch for each time\n",
    "            update_rate (0, 1): parameter for soft update\n",
    "            learning_rate(float): learning rate for SGD\n",
    "            memory_length(int): the length of Replay Memory\n",
    "            n_memory(int): the number of different Replay Memories\n",
    "            alpha, beta: [0, 1] parameters for Prioritized Replay Memories\n",
    "            action_scale(float): the scale of initialized ation\n",
    "        \"\"\"\n",
    "        self.device = config.device\n",
    "        self.save_path = config.save_path\n",
    "        self.is_load = config.is_load\n",
    "        self.gamma = config.gamma\n",
    "        self.history_length = config.history_length\n",
    "        self.n_stock = config.n_stock\n",
    "        self.n_feature = config.n_feature\n",
    "        self.n_smooth = config.n_smooth\n",
    "        self.n_down = config.n_down\n",
    "        self.k_w = config.k_w\n",
    "        self.n_hidden = config.n_hidden\n",
    "        self.n_batch = config.n_batch\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.update_rate = config.update_rate\n",
    "        self.alpha = config.alpha\n",
    "        self.beta = config.beta\n",
    "        self.lr = config.learning_rate\n",
    "        self.memory_length = config.memory_length\n",
    "        self.n_memory = config.n_memory\n",
    "        self.action_scale = config.action_scale\n",
    "        # the length of the data as input\n",
    "        self.n_history = max(self.n_smooth + self.history_length, (self.n_down + 1) * self.history_length)\n",
    "        print (\"building model....\")\n",
    "        # have compatibility with new tensorflow\n",
    "        tf.python.control_flow_ops = tf\n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "        K.set_session(self.sess)\n",
    "        with self.sess.as_default():\n",
    "            with tf.device(self.device):\n",
    "                self.build_model()\n",
    "        print('finished building model!')\n",
    "    \n",
    "    def train(self, input_data, noise_scale=0.1):\n",
    "        \"\"\"training DDPG, where action is confined to integer space\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): stock price for self.n_feature companies\n",
    "        \"\"\"\n",
    "        stock_data = input_data.values\n",
    "        date = input_data.index\n",
    "        T = len(stock_data)\n",
    "        self.noise_scale = noise_scale\n",
    "        \n",
    "        # frequency for output\n",
    "        print_freq = int(T / 100)\n",
    "        if print_freq == 0:\n",
    "            print_freq = 1\n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        # prioritizomg parameter\n",
    "        db = (1 - self.beta) / 1000\n",
    "        \n",
    "        # result for return value\n",
    "        values = [[] for _ in range(self.n_stock)]\n",
    "        date_label = [[] for _ in range(self.n_stock)]\n",
    "        date_use = []\n",
    "        stock_use = []\n",
    "        # keep half an year data \n",
    "        t0 = self.n_history + self.n_batch\n",
    "        self.initialize_memory(stock_data[:t0], scale=noise_scale)\n",
    "        plot_freq = 10\n",
    "        save_freq = 10\n",
    "        count = 0\n",
    "        input_data.to_csv(\"stock_price.csv\")\n",
    "        for t in range(t0, T):\n",
    "            stock_use.append(stock_data[t])\n",
    "            date_use.append(date[t])\n",
    "            action = self.predict_action(stock_data[t])\n",
    "            # print(self.memory[0].observations.data)\n",
    "            for i in range(self.n_stock):\n",
    "                if action[i] == 0:\n",
    "                    date_label[i].append(date[t])\n",
    "                    values[i].append(stock_data[t][i])\n",
    "            self.update_memory(stock_data[t])\n",
    "            count += 1\n",
    "            for epoch in range(self.n_epochs):    \n",
    "                # select transition from pool\n",
    "                self.update_weight()\n",
    "                # update prioritizing paramter untill it goes over 1\n",
    "            self.beta  += db\n",
    "            if self.beta >= 1.0:\n",
    "                self.beta = 1.0\n",
    "            idx = np.random.randint(0, self.n_memory)\n",
    "            \n",
    "            experiences, weights = self.memory[idx].sample(self.n_batch, self.n_history, self.alpha, self.beta)\n",
    "            max_idx = self.get_max_idx(experiences.state1)\n",
    "            target_value = self.sess.run(self.target_value,\n",
    "                                     feed_dict={self.state_target: experiences.state1,\n",
    "                                 self.reward: experiences.reward,\n",
    "                                               self.max_idx_target: max_idx})\n",
    "            \n",
    "            if t % print_freq == 0:\n",
    "                print (\"time:\",  date[t])\n",
    "                error = self.sess.run(self.error,\n",
    "                              feed_dict={self.state: experiences.state0,\n",
    "                                         self.target: target_value,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         K.learning_phase(): 0})\n",
    "                print(\"error:\", np.mean(error))\n",
    "                action = self.predict_action(stock_data[t])\n",
    "                print(\"portfolio:\", action)\n",
    "                print (\"elapsed time\", time.time() - st)\n",
    "                print(\"********************************************************************\")\n",
    "                \n",
    "            if count % plot_freq == 0:\n",
    "                for i in range(self.n_stock):\n",
    "                    result = pd.DataFrame(values[i], index=pd.DatetimeIndex(date_label[i]))\n",
    "                    result.to_csv(\"exit_result_{}.csv\".format(i))\n",
    "                data_use = pd.DataFrame(stock_use, index=pd.DatetimeIndex(date_use))\n",
    "                data_use.to_csv(\"stock_price.csv\")\n",
    "                \n",
    "            if count % save_freq == 0:\n",
    "                save_path = self.saver.save(self.sess, self.save_path)\n",
    "                print(\"Model saved in file: %s\" % self.save_path)\n",
    "\n",
    "        save_path = self.saver.save(self.sess, self.save_path)\n",
    "        print(\"Model saved in file: %s\" % self.save_path)\n",
    "        print (\"finished training\")\n",
    "        \n",
    "        return [pd.DataFrame(values[i], index=pd.DatetimeIndex(date_label[i])) for i in range(self.n_stock)]\n",
    "    \n",
    "    def predict_action(self, state):\n",
    "        \"\"\"Preduct Optimal Portfolio\n",
    "        \n",
    "        Args:\n",
    "            state(float): stock data with size: [self.n_stock, ]\n",
    "        Retrun:\n",
    "            np.array with size: [self.n_stock, ]\n",
    "        \"\"\"\n",
    "        pred_state = self.memory[0].sample_state_uniform(self.n_batch, self.n_history)\n",
    "        new_state = pred_state[-1]\n",
    "        new_state = np.concatenate((new_state[1:], [state]), axis=0)\n",
    "        pred_state = np.concatenate((pred_state[:-1], [new_state]), axis=0)\n",
    "        action = self.max_action.eval(\n",
    "            session=self.sess,\n",
    "            feed_dict={self.state: pred_state, K.learning_phase(): 0})[-1]\n",
    "        # action = self.norm_action(action)\n",
    "        return action\n",
    "    \n",
    "    def update_weight(self):\n",
    "        # pararel memory update\n",
    "        idx = np.random.randint(0, self.n_memory)\n",
    "        experiences, weights = self.memory[idx].sample(self.n_batch, self.n_history, self.alpha, self.beta)\n",
    "        max_idx = self.get_max_idx(experiences.state1)\n",
    "        \n",
    "        target_value = self.sess.run(self.target_value,\n",
    "                                     feed_dict={self.state_target: experiences.state1,\n",
    "                                 self.reward: experiences.reward,\n",
    "                                               self.max_idx_target: max_idx})\n",
    "\n",
    "        self.sess.run(self.critic_optim, \n",
    "                      feed_dict={self.state: experiences.state0,\n",
    "                                 self.target: target_value,\n",
    "                                 self.weights: weights,\n",
    "                                 self.learning_rate: self.lr,\n",
    "                                 K.learning_phase(): 1})  \n",
    "\n",
    "        error = self.sess.run(self.error,\n",
    "                              feed_dict={self.state: experiences.state0,\n",
    "                                         self.target: target_value,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         K.learning_phase(): 0})\n",
    "        self.memory[idx].update_priority(error)\n",
    "        \n",
    "                    \n",
    "        # softupdate for critic network\n",
    "        old_weights = self.critic_target.get_weights()\n",
    "        new_weights = self.critic.get_weights()\n",
    "        weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w\n",
    "                   for new_w, old_w in zip(new_weights, old_weights)]\n",
    "        self.critic_target.set_weights(weights)\n",
    "        \n",
    "    def initialize_memory(self, stocks, scale=10):\n",
    "        self.memory = []\n",
    "        for i in range(self.n_memory):\n",
    "            self.memory.append(SequentialMemory(self.memory_length))\n",
    "        for t in range(len(stocks)):\n",
    "            for idx_memory in range(self.n_memory):\n",
    "                action = None\n",
    "                reward = np.concatenate((np.reshape(stocks[t], (self.n_stock, 1)), np.zeros((self.n_stock, 1))), axis=-1)\n",
    "                self.memory[idx_memory].append(stocks[t], action, reward)\n",
    "        \n",
    "    def update_memory(self, state):\n",
    "        # update memory without updating weight\n",
    "        for i in range(self.n_memory):\n",
    "            self.memory[i].observations.append(state)\n",
    "            self.memory[i].priority.append(1.0)\n",
    "        # to stabilize batch normalization, use other samples for prediction\n",
    "        pred_state = self.memory[0].sample_state_uniform(self.n_batch, self.n_history)\n",
    "        for i in range(self.n_memory):\n",
    "            action_off = None\n",
    "            reward_off = np.concatenate((np.reshape(state, (self.n_stock, 1)), np.zeros((self.n_stock, 1))), axis=-1)\n",
    "            self.memory[i].rewards.append(reward_off)\n",
    "            self.memory[i].actions.append(action_off)\n",
    "    \n",
    "    def get_max_idx(self, state):\n",
    "        max_action = self.sess.run(self.max_action_target, feed_dict={self.state_target: state})\n",
    "        shape = max_action.shape\n",
    "        max_idx = []\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                max_idx.append([i, j, max_action[i][j]])\n",
    "        return np.array(max_idx, dtype=int)\n",
    "    \n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build all of the network and optimizations\n",
    "        \n",
    "        just for conveninece of trainig, seprate placehoder for train and target network\n",
    "        critic network input: [raw_data, smoothed, downsampled, action]\n",
    "        actor network input: [raw_data, smoothed, downsampled]\n",
    "        \"\"\"\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic_target = self.build_critic()\n",
    "        # transform input into the several scales and smoothing\n",
    "        self.state =  tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state')\n",
    "        self.state_target = tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state_target')\n",
    "        # reshape to convolutional input\n",
    "        state_ = tf.reshape(self.state, [-1, self.n_history, self.n_stock, 1])\n",
    "        state_target_ = tf.reshape(self.state_target, [-1, self.n_history, self.n_stock, 1])\n",
    "        raw, smoothed, down = self.transform_input(state_)\n",
    "        raw_target, smoothed_target, down_target = self.transform_input(state_target_)\n",
    "        \n",
    "        # build graph for citic training\n",
    "        input_q = [raw,] +  smoothed + down\n",
    "        self.Q = self.critic(input_q)\n",
    "        self.max_action = tf.argmax(self.Q, dimension=2)\n",
    "        # target network\n",
    "        input_q_target = [raw_target,] +  smoothed_target + down_target\n",
    "        Q_target = self.critic_target(input_q_target)\n",
    "        self.reward = tf.placeholder(tf.float32, [None, self.n_stock, 2], name='reward')\n",
    "        double_Q = self.critic(input_q_target)\n",
    "        self.max_action_target = tf.argmax(double_Q, 2)\n",
    "        self.max_idx_target = tf.placeholder(tf.int32, [None, 3], \"double_idx\")\n",
    "        Q_max = tf.gather_nd(Q_target, self.max_idx_target)\n",
    "        Q_max = tf.reshape(Q_max, [-1, self.n_stock, 1])\n",
    "        Q_value = tf.concat(2, (tf.zeros_like(Q_max), Q_max))\n",
    "        self.target_value = self.reward  + self.gamma * Q_value\n",
    "        self.target_value = tf.cast(self.target_value, tf.float32)\n",
    "        self.target = tf.placeholder(tf.float32, [None, self.n_stock, 2], name=\"target_value\")\n",
    "        # optimization\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        # get rid of bias of prioritized\n",
    "        self.weights = tf.placeholder(tf.float32, shape=[None], name=\"weights\")\n",
    "        self.loss = tf.reduce_mean(self.weights * tf.reduce_sum(tf.square(self.target - self.Q), [1, 2]), name='loss')\n",
    "        # TD-error for priority\n",
    "        self.error = tf.reduce_sum(tf.abs(self.target - self.Q), [1, 2])\n",
    "        self.critic_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(self.loss, var_list=self.critic.trainable_weights)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        is_initialize = True\n",
    "        if self.is_load:\n",
    "            if self.load(self.save_path):\n",
    "                print('succeded to load')\n",
    "                is_initialize = False\n",
    "            else:\n",
    "                print('failed to load')\n",
    "        \n",
    "        # initialize network\n",
    "        tf.initialize_all_variables().run(session=self.sess)\n",
    "        weights = self.critic.get_weights()\n",
    "        self.critic_target.set_weights(weights)\n",
    "        \n",
    "    def build_critic(self):\n",
    "        \"\"\"Build critic network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        nf = self.n_feature\n",
    "        # layer1\n",
    "        # smoothed input\n",
    "        sm_model = [Sequential() for _ in range(self.n_smooth)]\n",
    "        for m in sm_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # down sampled input\n",
    "        dw_model = [Sequential() for _ in range(self.n_down)]\n",
    "        for m in dw_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # raw input\n",
    "        state = Sequential()\n",
    "        nf = self.n_feature\n",
    "        state.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "        # state.add(SpatialDropout2D(0.2))\n",
    "        state.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        state.add(BatchNormalization(mode=2, axis=-1))\n",
    "        state.add(PReLU())\n",
    "        merged = Merge([state,] + sm_model + dw_model, mode='concat', concat_axis=-1)\n",
    "        # layer2\n",
    "        nf = nf * 2\n",
    "        model = Sequential()\n",
    "        model.add(merged)\n",
    "        # merged_state.add(SpatialDropout2D(0.2))\n",
    "        model.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        model.add(BatchNormalization(mode=2, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        model.add(Flatten())\n",
    "        # layer3\n",
    "        model.add(Dense(self.n_hidden))\n",
    "        model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # layer4\n",
    "        # model.add(Dropout(0.5))\n",
    "        model.add(Dense(int(np.sqrt(self.n_hidden))))\n",
    "        # model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # output\n",
    "        # model.add(Dropout(0.5))\n",
    "        model.add(Dense(2 * self.n_stock))\n",
    "        model.add(Reshape((self.n_stock, 2)))\n",
    "        return model\n",
    "    \n",
    "    def transform_input(self, input):\n",
    "        \"\"\"Transform data into the Multi Scaled one\n",
    "        \n",
    "        Args:\n",
    "            input: tensor with shape: [None, self.n_history, self.n_stock]\n",
    "        Return:\n",
    "            list of the same shape tensors, [None, self.length_history, self.n_stock]\n",
    "        \"\"\"\n",
    "        # the last data is the newest information\n",
    "        raw = input[:, self.n_history - self.history_length:, :, :]\n",
    "        # smooth data\n",
    "        smoothed = []\n",
    "        for n_sm in range(2, self.n_smooth + 2):\n",
    "            smoothed.append(\n",
    "                tf.reduce_mean(tf.pack([input[:, self.n_history - st - self.history_length:self.n_history - st, :, :]\n",
    "                                        for st in range(n_sm)]),0))\n",
    "        # downsample data\n",
    "        down = []\n",
    "        for n_dw in range(2, self.n_down + 2):\n",
    "            sampled_ = tf.pack([input[:, idx, :, :] \n",
    "                                for idx in range(self.n_history-n_dw*self.history_length, self.n_history, n_dw)])\n",
    "            down.append(tf.transpose(sampled_, [1, 0, 2, 3]))\n",
    "        return raw, smoothed, down\n",
    "    \n",
    "    def load(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        try:\n",
    "            self.saver.restore(self.sess, self.save_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "n_stock = len(input_data.values[0])\n",
    "# n_stock = 10\n",
    "\n",
    "class DQNConfig(object):\n",
    "    device = '/cpu:0'\n",
    "    save_path = '/home/tomoaki/work/github/DQN/DDPG_model.ckpt'\n",
    "    is_load = False\n",
    "    activation = 'relu'\n",
    "    gamma = 1 - 1.0e-4\n",
    "    history_length = 10\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 100\n",
    "    n_feature = 32\n",
    "    alpha = 0.7\n",
    "    beta = 0.5\n",
    "    update_rate = 1e-1\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    # memory_config\n",
    "    memory_length = 200\n",
    "    n_memory = 10\n",
    "    action_scale = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n",
      "finished building model!\n",
      "start!\n",
      "training....\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-04-13 00:00:00\n",
      "error: 0.244938\n",
      "portfolio: [0]\n",
      "elapsed time 82.9970369339\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-05-15 00:00:00\n",
      "error: 0.222701\n",
      "portfolio: [1]\n",
      "elapsed time 179.724574089\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-06-15 00:00:00\n",
      "error: 0.202535\n",
      "portfolio: [1]\n",
      "elapsed time 275.936066866\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-07-18 00:00:00\n",
      "error: 0.30716\n",
      "portfolio: [1]\n",
      "elapsed time 372.308498859\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-08-17 00:00:00\n",
      "error: 0.17651\n",
      "portfolio: [1]\n",
      "elapsed time 468.871201038\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-09-19 00:00:00\n",
      "error: 0.160649\n",
      "portfolio: [1]\n",
      "elapsed time 566.049052\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-10-19 00:00:00\n",
      "error: 0.34038\n",
      "portfolio: [1]\n",
      "elapsed time 663.469980001\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-11-20 00:00:00\n",
      "error: 0.454053\n",
      "portfolio: [1]\n",
      "elapsed time 760.032361031\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2007-12-21 00:00:00\n",
      "error: 0.241491\n",
      "portfolio: [1]\n",
      "elapsed time 856.957815886\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-01-25 00:00:00\n",
      "error: 0.263008\n",
      "portfolio: [1]\n",
      "elapsed time 953.659445047\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-02-27 00:00:00\n",
      "error: 0.20776\n",
      "portfolio: [1]\n",
      "elapsed time 1050.66596389\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-03-31 00:00:00\n",
      "error: 0.135274\n",
      "portfolio: [1]\n",
      "elapsed time 1147.62832189\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-04-30 00:00:00\n",
      "error: 0.373435\n",
      "portfolio: [1]\n",
      "elapsed time 1244.39155889\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-06-02 00:00:00\n",
      "error: 0.228437\n",
      "portfolio: [1]\n",
      "elapsed time 1341.0384419\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-07-02 00:00:00\n",
      "error: 0.163748\n",
      "portfolio: [1]\n",
      "elapsed time 1438.02355886\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-08-04 00:00:00\n",
      "error: 0.119361\n",
      "portfolio: [1]\n",
      "elapsed time 1534.61001587\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-09-04 00:00:00\n",
      "error: 0.193875\n",
      "portfolio: [1]\n",
      "elapsed time 1631.55857897\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-10-06 00:00:00\n",
      "error: 0.24498\n",
      "portfolio: [1]\n",
      "elapsed time 1727.63387489\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-11-05 00:00:00\n",
      "error: 0.223584\n",
      "portfolio: [1]\n",
      "elapsed time 1823.81149292\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2008-12-08 00:00:00\n",
      "error: 0.280213\n",
      "portfolio: [1]\n",
      "elapsed time 1920.107306\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-01-09 00:00:00\n",
      "error: 0.202043\n",
      "portfolio: [1]\n",
      "elapsed time 2016.590693\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-02-11 00:00:00\n",
      "error: 0.267658\n",
      "portfolio: [1]\n",
      "elapsed time 2113.46254086\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-03-16 00:00:00\n",
      "error: 0.270738\n",
      "portfolio: [1]\n",
      "elapsed time 2209.72742295\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-04-16 00:00:00\n",
      "error: 0.139996\n",
      "portfolio: [1]\n",
      "elapsed time 2306.45927787\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-05-18 00:00:00\n",
      "error: 0.483466\n",
      "portfolio: [1]\n",
      "elapsed time 2402.75278306\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-06-18 00:00:00\n",
      "error: 0.275064\n",
      "portfolio: [1]\n",
      "elapsed time 2499.30124593\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-07-21 00:00:00\n",
      "error: 0.142936\n",
      "portfolio: [1]\n",
      "elapsed time 2596.10454488\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-08-20 00:00:00\n",
      "error: 0.387306\n",
      "portfolio: [1]\n",
      "elapsed time 2692.64885187\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-09-22 00:00:00\n",
      "error: 0.181462\n",
      "portfolio: [1]\n",
      "elapsed time 2789.03554392\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-10-22 00:00:00\n",
      "error: 0.464058\n",
      "portfolio: [1]\n",
      "elapsed time 2885.79306197\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-11-23 00:00:00\n",
      "error: 0.346292\n",
      "portfolio: [1]\n",
      "elapsed time 2982.43806291\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2009-12-24 00:00:00\n",
      "error: 0.468111\n",
      "portfolio: [1]\n",
      "elapsed time 3079.62506294\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-01-28 00:00:00\n",
      "error: 0.279549\n",
      "portfolio: [1]\n",
      "elapsed time 3176.1013\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-03-02 00:00:00\n",
      "error: 0.394225\n",
      "portfolio: [1]\n",
      "elapsed time 3272.87414908\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-04-01 00:00:00\n",
      "error: 0.262612\n",
      "portfolio: [1]\n",
      "elapsed time 3369.38375807\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-05-04 00:00:00\n",
      "error: 0.190274\n",
      "portfolio: [1]\n",
      "elapsed time 3465.85702205\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-06-04 00:00:00\n",
      "error: 0.289004\n",
      "portfolio: [1]\n",
      "elapsed time 3562.92251086\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-07-07 00:00:00\n",
      "error: 0.134339\n",
      "portfolio: [1]\n",
      "elapsed time 3659.26375294\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-08-06 00:00:00\n",
      "error: 0.268961\n",
      "portfolio: [1]\n",
      "elapsed time 3756.00944996\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-09-08 00:00:00\n",
      "error: 0.167409\n",
      "portfolio: [1]\n",
      "elapsed time 3852.48381591\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-10-08 00:00:00\n",
      "error: 0.12713\n",
      "portfolio: [1]\n",
      "elapsed time 3949.16164088\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-11-09 00:00:00\n",
      "error: 0.148832\n",
      "portfolio: [1]\n",
      "elapsed time 4046.25979805\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2010-12-10 00:00:00\n",
      "error: 0.0689617\n",
      "portfolio: [1]\n",
      "elapsed time 4143.01591802\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-01-12 00:00:00\n",
      "error: 0.069814\n",
      "portfolio: [0]\n",
      "elapsed time 4239.29201388\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-02-14 00:00:00\n",
      "error: 0.188656\n",
      "portfolio: [1]\n",
      "elapsed time 4336.28480601\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-03-17 00:00:00\n",
      "error: 0.198931\n",
      "portfolio: [1]\n",
      "elapsed time 4432.81366301\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-04-18 00:00:00\n",
      "error: 0.335276\n",
      "portfolio: [0]\n",
      "elapsed time 4530.12215495\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-05-19 00:00:00\n",
      "error: 0.263124\n",
      "portfolio: [1]\n",
      "elapsed time 4627.14289188\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-06-21 00:00:00\n",
      "error: 0.252055\n",
      "portfolio: [1]\n",
      "elapsed time 4723.57590103\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-07-22 00:00:00\n",
      "error: 0.124821\n",
      "portfolio: [1]\n",
      "elapsed time 4820.15697408\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-08-23 00:00:00\n",
      "error: 0.0565333\n",
      "portfolio: [1]\n",
      "elapsed time 4916.71420789\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-09-23 00:00:00\n",
      "error: 0.159495\n",
      "portfolio: [1]\n",
      "elapsed time 5013.88453507\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-10-25 00:00:00\n",
      "error: 0.09701\n",
      "portfolio: [1]\n",
      "elapsed time 5110.4785769\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-11-25 00:00:00\n",
      "error: 0.248151\n",
      "portfolio: [1]\n",
      "elapsed time 5207.32517505\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2011-12-28 00:00:00\n",
      "error: 0.235043\n",
      "portfolio: [1]\n",
      "elapsed time 5303.89828396\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-01-31 00:00:00\n",
      "error: 0.101635\n",
      "portfolio: [1]\n",
      "elapsed time 5400.65219307\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-03-02 00:00:00\n",
      "error: 0.13941\n",
      "portfolio: [1]\n",
      "elapsed time 5497.70315099\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-04-03 00:00:00\n",
      "error: 0.109673\n",
      "portfolio: [1]\n",
      "elapsed time 5594.72568893\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-05-04 00:00:00\n",
      "error: 0.186953\n",
      "portfolio: [1]\n",
      "elapsed time 5691.52580595\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-06-06 00:00:00\n",
      "error: 0.249095\n",
      "portfolio: [1]\n",
      "elapsed time 5788.33909202\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-07-09 00:00:00\n",
      "error: 0.0880406\n",
      "portfolio: [1]\n",
      "elapsed time 5884.99931908\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-08-08 00:00:00\n",
      "error: 0.103021\n",
      "portfolio: [1]\n",
      "elapsed time 5982.15605187\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-09-10 00:00:00\n",
      "error: 0.280502\n",
      "portfolio: [1]\n",
      "elapsed time 6078.76988292\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-10-10 00:00:00\n",
      "error: 0.0698627\n",
      "portfolio: [1]\n",
      "elapsed time 6175.24001503\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-11-13 00:00:00\n",
      "error: 0.0863414\n",
      "portfolio: [1]\n",
      "elapsed time 6271.94921398\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2012-12-14 00:00:00\n",
      "error: 0.118311\n",
      "portfolio: [1]\n",
      "elapsed time 6368.33416104\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-01-17 00:00:00\n",
      "error: 0.0991505\n",
      "portfolio: [1]\n",
      "elapsed time 6465.31202507\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-02-20 00:00:00\n",
      "error: 0.0630394\n",
      "portfolio: [1]\n",
      "elapsed time 6561.74110699\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-03-22 00:00:00\n",
      "error: 0.0939115\n",
      "portfolio: [1]\n",
      "elapsed time 6658.28745794\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-04-24 00:00:00\n",
      "error: 0.0895143\n",
      "portfolio: [1]\n",
      "elapsed time 6754.75699186\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-05-24 00:00:00\n",
      "error: 0.105885\n",
      "portfolio: [1]\n",
      "elapsed time 6851.35448503\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-06-26 00:00:00\n",
      "error: 0.113911\n",
      "portfolio: [1]\n",
      "elapsed time 6948.20720005\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-07-29 00:00:00\n",
      "error: 0.0535152\n",
      "portfolio: [0]\n",
      "elapsed time 7044.82954907\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-08-28 00:00:00\n",
      "error: 0.229323\n",
      "portfolio: [0]\n",
      "elapsed time 7141.2510159\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-09-30 00:00:00\n",
      "error: 0.0699025\n",
      "portfolio: [0]\n",
      "elapsed time 7237.82211709\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-10-30 00:00:00\n",
      "error: 0.109388\n",
      "portfolio: [1]\n",
      "elapsed time 7334.239887\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2013-12-02 00:00:00\n",
      "error: 0.187619\n",
      "portfolio: [0]\n",
      "elapsed time 7431.18802691\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-01-03 00:00:00\n",
      "error: 0.2325\n",
      "portfolio: [1]\n",
      "elapsed time 7527.88246703\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-02-05 00:00:00\n",
      "error: 0.414204\n",
      "portfolio: [1]\n",
      "elapsed time 7624.41279888\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-03-10 00:00:00\n",
      "error: 0.141665\n",
      "portfolio: [1]\n",
      "elapsed time 7721.33697891\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-04-09 00:00:00\n",
      "error: 0.334646\n",
      "portfolio: [1]\n",
      "elapsed time 7817.79111099\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-05-12 00:00:00\n",
      "error: 0.177815\n",
      "portfolio: [1]\n",
      "elapsed time 7914.8549459\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-06-12 00:00:00\n",
      "error: 0.449793\n",
      "portfolio: [1]\n",
      "elapsed time 8011.25662398\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-07-15 00:00:00\n",
      "error: 0.189043\n",
      "portfolio: [1]\n",
      "elapsed time 8107.97426295\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-08-14 00:00:00\n",
      "error: 0.169053\n",
      "portfolio: [1]\n",
      "elapsed time 8204.55173588\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-09-16 00:00:00\n",
      "error: 0.167914\n",
      "portfolio: [1]\n",
      "elapsed time 8301.32406688\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-10-16 00:00:00\n",
      "error: 0.190151\n",
      "portfolio: [1]\n",
      "elapsed time 8398.2424109\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-11-17 00:00:00\n",
      "error: 0.102052\n",
      "portfolio: [1]\n",
      "elapsed time 8494.88079\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2014-12-18 00:00:00\n",
      "error: 0.119808\n",
      "portfolio: [1]\n",
      "elapsed time 8591.21196294\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-01-22 00:00:00\n",
      "error: 0.281042\n",
      "portfolio: [1]\n",
      "elapsed time 8687.86775708\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-02-24 00:00:00\n",
      "error: 0.148004\n",
      "portfolio: [1]\n",
      "elapsed time 8784.32209992\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-03-26 00:00:00\n",
      "error: 0.115482\n",
      "portfolio: [1]\n",
      "elapsed time 8881.30152893\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-04-28 00:00:00\n",
      "error: 0.162808\n",
      "portfolio: [1]\n",
      "elapsed time 8977.894063\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-05-29 00:00:00\n",
      "error: 0.248601\n",
      "portfolio: [1]\n",
      "elapsed time 9074.46432686\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-06-30 00:00:00\n",
      "error: 0.117115\n",
      "portfolio: [1]\n",
      "elapsed time 9171.13926888\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-07-31 00:00:00\n",
      "error: 0.292096\n",
      "portfolio: [1]\n",
      "elapsed time 9267.89155102\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "time: 2015-09-01 00:00:00\n",
      "error: 0.16194\n",
      "portfolio: [1]\n",
      "elapsed time 9364.89893389\n",
      "********************************************************************\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "Model saved in file: /home/tomoaki/work/github/DQN/DDPG_model.ckpt\n",
      "finished training\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# from model import DDPG\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = DQNConfig()\n",
    "\n",
    "dqn = DQN(config)\n",
    "print (\"start!\")\n",
    "values = dqn.train(train_data)\n",
    "print (\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 9\n",
    "\n",
    "plt.scatter(values[i].index, values[i].values)\n",
    "plt.plot(input_tilde.index, input_tilde.values[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
