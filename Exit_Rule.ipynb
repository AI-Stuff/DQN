{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_list = ['MMM', 'T', 'ABBV', 'ABT', 'ACN', 'AGN', 'ALL', 'GOOGL', \n",
    "              'GOOG', 'MO', 'AMZN', 'AXP', 'AIG', 'AMGN', 'AAPL', 'BAC', 'BIIB', \n",
    "              'BLK', 'BA', 'BMY', 'CVS', 'COF', 'CAT', 'CELG', 'CVX', 'CSCO', 'C', \n",
    "              'KO', 'CL', 'CMCSA', 'COP', 'COST', 'DHR', 'DOW', 'DUK', 'DD', 'EMC', \n",
    "              'EMR', 'EXC', 'XOM', 'FB', 'FDX', 'F', 'GD', 'GE', 'GM', 'GILD', 'GS', 'HAL', \n",
    "              'HD', 'HON', 'INTC', 'IBM', 'JPM', 'JNJ', 'KMI', 'LLY', 'LMT', 'LOW', 'MA', \n",
    "              'MCD', 'MDT', 'MRK', 'MET', 'MSFT', 'MDLZ', 'MON', 'MS', 'NKE', 'OXY', \n",
    "              'ORCL', 'PEP', 'PFE', 'PM', 'PG', 'QCOM', 'RTN', 'SLB', 'SPG', 'SO', 'SBUX', \n",
    "              'TGT', 'TXN', 'BK', 'PCLN', 'TWX', 'FOXA', 'FOX', 'USB', 'UNP', 'UPS', 'UTX', \n",
    "              'UNH', 'VZ', 'V', 'WMT', 'WBA', 'DIS', 'WFC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!!\n",
      "fail_name_list:  []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cdc8e6c48c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2014-04-01\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2016-04-01\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fixed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"time for getting data:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/work/github/DQN/utils.py\u001b[0m in \u001b[0;36mget_fixed_data\u001b[0;34m(name_list, start_date, end_date, data_type)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mdate_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datetime_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mstock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print (\"Started!!\")\n",
    "\n",
    "st = time.time()\n",
    "start_date=\"2014-04-01\"\n",
    "end_date=\"2016-04-01\"\n",
    "input_data, input_list = utils.get_fixed_data(input_list, start_date=start_date, end_date=end_date) \n",
    "elapsed = time.time() - st\n",
    "print (\"time for getting data:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_value = input_data.values\n",
    "index = input_data.index\n",
    "input_tilde = pd.DataFrame(input_value[:, :10], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (input_tilde.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(input_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG for trading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data, you are going to learn how to manage your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "# n_stock = len(input_tilde.values[0])\n",
    "n_stock = 10\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 6\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 10\n",
    "    n_feature = 5\n",
    "    update_rate = 1e-1\n",
    "    learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.date_range('23/10/2016', periods=100, freq='D')\n",
    "value = np.random.normal(0, 1, (len(index), n_stock))\n",
    "input_data = pd.DataFrame(value, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "import numpy as np\n",
    "\n",
    "Experiecne = namedtuple('Experience', 'state0, reward, state1')\n",
    "\n",
    "class RingBuffer(object):\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.start = 0\n",
    "        self.length = 0\n",
    "        # self.data = [None for _ in range(maxlen)]\n",
    "        self.data = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx< 0 or idx >= self.length:\n",
    "            raise KeyError()\n",
    "        return self.data[(self.start + idx) % self.maxlen]\n",
    "    \n",
    "    def append(self, v):\n",
    "        if self.length < self.maxlen:\n",
    "            # We have space, simply increase the length\n",
    "            self.length += 1\n",
    "        elif self.length == self.maxlen:\n",
    "            # No space, \"remove\" the first item\n",
    "            self.data[:-1] = self.data[1:]\n",
    "        else:\n",
    "            # This should never happen\n",
    "            raise RuntimeError()\n",
    "        self.data.append(v)\n",
    "        \n",
    "class SequentialMemory(object):\n",
    "    def __init__(self, limit=1000):\n",
    "        self.limit = limit\n",
    "        \n",
    "        self.rewards = RingBuffer(limit)\n",
    "        self.observations = RingBuffer(limit)\n",
    "        \n",
    "    def sample(self, batch_size, window_length):\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        batch_idx = np.random.random_integers(window_length, self.nb_entries - 1, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries - 1]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state0 = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        reward = np.array([self.rewards[idx - 1] for idx in batch_idx])\n",
    "        state1 = np.array([[self.observations[i] for i in range(idx - window_length + 1,idx + 1)] for idx in batch_idx])\n",
    "        return Experiecne(state0, reward, state1)\n",
    "    \n",
    "    def sample_state(self, batch_size, window_length):\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        batch_idx = np.random.random_integers(window_length, self.nb_entries - 1, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length, idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def append(self, observation, reward):\n",
    "        self.observations.append(observation)\n",
    "        self.rewards.append(reward)  \n",
    "    \n",
    "    @property\n",
    "    def nb_entries(self):\n",
    "        return  len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# from memory import SequentialMemory\n",
    "\n",
    "class DQN(object):\n",
    "    \"\"\"Deep Deterministic Poilicy Gradient\n",
    "    \n",
    "    Basend on DPG and Multiscale CNN, seek out \n",
    "    optimal strategy for stock trading.\n",
    "    \n",
    "    Available function\n",
    "    - build_model: build network basedon tensorflow and keras\n",
    "    - train: given DateFrame stock data, train network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        config should have the following attributes\n",
    "        \n",
    "        Args:\n",
    "            gamma(float): the decay rate for value at RL\n",
    "            history_length(int): input_length for each scale at CNN\n",
    "            n_feature(int): the number of type of input \n",
    "                (e.g. the number of company to use at stock trading)\n",
    "            trade_stock_idx(int): trading stock index\n",
    "            gam (float): discount factor\n",
    "            n_history(int): the nubmer of history that will be used as input\n",
    "            n_smooth, n_down(int): the number of smoothed and down sampling input at CNN\n",
    "            k_w(int): the size of filter at CNN\n",
    "            n_hidden(int): the size of fully connected layer\n",
    "            n_batch(int): the size of mini batch\n",
    "            n_epochs(int): the training epoch for each time\n",
    "            update_rate (0, 1): parameter for soft update\n",
    "            learning_rate(float): learning rate for SGD\n",
    "        \"\"\"\n",
    "        self.gamma = config.gamma\n",
    "        self.history_length = config.history_length\n",
    "        self.n_stock = config.n_stock\n",
    "        self.n_feature = config.n_feature\n",
    "        self.n_smooth = config.n_smooth\n",
    "        self.n_down = config.n_down\n",
    "        self.k_w = config.k_w\n",
    "        self.n_hidden = config.n_hidden\n",
    "        self.n_batch = config.n_batch\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.update_rate = config.update_rate\n",
    "        self.lr = config.learning_rate\n",
    "        # the actual dimention of input\n",
    "        self.n_input = (1 + self.n_smooth + self.n_down) * self.n_stock\n",
    "        # the length of the data as input\n",
    "        self.n_history = max(self.n_smooth + self.history_length , (self.n_down + 1) * self.history_length)\n",
    "        print (\"building model....\")\n",
    "        # have compatibility with new tensorflow\n",
    "        tf.python.control_flow_ops = tf\n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "        K.set_session(self.sess)\n",
    "        with self.sess.as_default():\n",
    "            self.build_model()\n",
    "        print('finished building model!')\n",
    "    \n",
    "    def train(self, input_data, noise_scale=2.0):\n",
    "        \"\"\"training DDPG, where action is confined to integer space\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): stock price for self.n_feature companies\n",
    "        \"\"\"\n",
    "        stock_data = input_data.values\n",
    "        date_data = input_data.index\n",
    "        T = len(stock_data)\n",
    "        \n",
    "        # frequency for output\n",
    "        print_freq = int(T / 100)\n",
    "        if print_freq == 0:\n",
    "            print_freq = 1\n",
    "            \n",
    "        print_freq = 1\n",
    "            \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        # the number of poassed stocks for each company\n",
    "        # result for return value\n",
    "        values = []\n",
    "        dates = []\n",
    "        for i in range(self.n_stock):\n",
    "            values.append([])\n",
    "            dates.append([])\n",
    "        # keep half an year data \n",
    "        memory = SequentialMemory(360)\n",
    "        for t in range(T):\n",
    "            price = stock_data[t]\n",
    "            reward = np.concatenate((np.reshape(stock_data[t], (self.n_stock, 1)), np.zeros((self.n_stock, 1))), axis=-1)\n",
    "            memory.append(price, reward)\n",
    "            # until having enough data, just do nothing\n",
    "            if t <= self.n_history + self.n_batch:\n",
    "                continue\n",
    "            # to stabilize batch normalization, use other samples for prediction\n",
    "            pred_state = memory.sample_state(self.n_batch, self.n_history)\n",
    "            # update network\n",
    "            action_value = self.sess.run(self.action,\n",
    "                                      feed_dict={self.state: pred_state,\n",
    "                                                K.learning_phase(): 0})[-1]\n",
    "            # add return value when exit value is better\n",
    "            for i in range(self.n_stock):\n",
    "                if action_value[i] == 0:\n",
    "                    values[i].append(price[i])\n",
    "                    dates[i].append(date_data[t])\n",
    "                    \n",
    "            for epoch in range(self.n_epochs):    \n",
    "                # select transition from pool\n",
    "                experiences = memory.sample(self.n_batch, self.n_history)\n",
    "                self.sess.run(self.critic_optim, \n",
    "                              feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.learning_rate: self.lr,\n",
    "                                         K.learning_phase(): 1})  \n",
    "                \n",
    "                loss = self.sess.run(self.loss, feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         K.learning_phase(): 0})\n",
    "                \n",
    "                \"\"\"\n",
    "                target_value = self.sess.run(self.target_value, feed_dict={\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         self.portfolio_target: experiences.portfolio1,\n",
    "                                         K.learning_phase(): 0})\n",
    "                \"\"\"\n",
    "                # print('critic_value', critic_value)\n",
    "                \n",
    "                \n",
    "                # print('target:', np.mean(target_value))\n",
    "                # print('Q_value:', np.mean(target_value - experiences.reward))\n",
    "                # print('reward:', np.mean(experiences.reward))\n",
    "                    \n",
    "                # softupdate for critic network\n",
    "                old_weights = self.critic_target.get_weights()\n",
    "                new_weights = self.critic.get_weights()\n",
    "                weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w for new_w, old_w in zip(new_weights, old_weights)]\n",
    "                self.critic_target.set_weights(weights)         \n",
    "                 \n",
    "            if t % print_freq == 0:\n",
    "                print (\"time:\",  date_data[t])\n",
    "                print('loss:', loss)\n",
    "                print (\"elapsed time\", time.time() - st)    \n",
    "\n",
    "        print (\"finished training\")\n",
    "        \n",
    "        ret_val = []\n",
    "        for i in range(self.n_stock):\n",
    "            ret_val.append(pd.DataFrame(values[i], index=pd.DatetimeIndex(dates[i])))\n",
    "        return ret_val\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build all of the network and optimizations\n",
    "        \n",
    "        just for conveninece of trainig, seprate placehoder for train and target network\n",
    "        critic network input: [raw_data, smoothed, downsampled, action]\n",
    "        actor network input: [raw_data, smoothed, downsampled]\n",
    "        \"\"\"\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic_target = self.build_critic()\n",
    "        # transform input into the several scales and smoothing\n",
    "        self.state =  tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state')\n",
    "        self.state_target = tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state_target')\n",
    "        # reshape to convolutional input\n",
    "        state_ = tf.reshape(self.state, [-1, self.n_history, self.n_stock, 1])\n",
    "        state_target_ = tf.reshape(self.state_target, [-1, self.n_history, self.n_stock, 1])\n",
    "        raw, smoothed, down = self.transform_input(state_)\n",
    "        raw_target, smoothed_target, down_target = self.transform_input(state_target_)\n",
    "        \n",
    "        # build graph for citic training\n",
    "        input_q = [raw,] +  smoothed + down\n",
    "        self.Q = self.critic(input_q)\n",
    "        self.action = tf.argmax(self.Q, dimension=2)\n",
    "        # target network\n",
    "        input_q_target = [raw_target,] +  smoothed_target + down_target\n",
    "        Q_target = self.critic_target(input_q_target)\n",
    "        self.reward = tf.placeholder(tf.float32, [None, self.n_stock, 2], name='reward')\n",
    "        Q_max =  tf.reshape(tf.reduce_max(Q_target, reduction_indices=[2]), [-1, self.n_stock, 1])\n",
    "        Q_value = tf.concat(2, (tf.zeros_like(Q_max), Q_max))\n",
    "        self.target = self.reward  + self.gamma * Q_value\n",
    "        # optimization\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        self.loss = tf.reduce_mean(tf.square(self.target - self.Q), name='loss')\n",
    "        self.critic_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(self.loss, var_list=self.critic.trainable_weights)\n",
    "        \n",
    "        # initialize network\n",
    "        tf.initialize_all_variables().run(session=self.sess)\n",
    "        weights = self.critic.get_weights()\n",
    "        self.critic_target.set_weights(weights)\n",
    "        \n",
    "    def build_critic(self):\n",
    "        \"\"\"Build critic network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        nf = self.n_feature\n",
    "        # layer1\n",
    "        # smoothed input\n",
    "        sm_model = [Sequential() for _ in range(self.n_smooth)]\n",
    "        for m in sm_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # down sampled input\n",
    "        dw_model = [Sequential() for _ in range(self.n_down)]\n",
    "        for m in dw_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # raw input\n",
    "        state = Sequential()\n",
    "        nf = self.n_feature\n",
    "        state.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "        # state.add(SpatialDropout2D(0.2))\n",
    "        state.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        state.add(BatchNormalization(mode=2, axis=-1))\n",
    "        state.add(PReLU())\n",
    "        merged = Merge([state,] + sm_model + dw_model, mode='concat', concat_axis=-1)\n",
    "        # layer2\n",
    "        nf = nf * 2\n",
    "        model = Sequential()\n",
    "        model.add(merged)\n",
    "        # merged_state.add(SpatialDropout2D(0.2))\n",
    "        model.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        model.add(BatchNormalization(mode=2, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        model.add(Flatten())\n",
    "        # layer3\n",
    "        model.add(Dense(self.n_hidden))\n",
    "        model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # layer4\n",
    "        # model.add(Dropout(0.5))\n",
    "        model.add(Dense(int(np.sqrt(self.n_hidden))))\n",
    "        # model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # output\n",
    "        # model.add(Dropout(0.5))\n",
    "        model.add(Dense(2 * self.n_stock))\n",
    "        model.add(Reshape((self.n_stock, 2)))\n",
    "        return model\n",
    "    \n",
    "    def transform_input(self, input):\n",
    "        # the last data is the newest information\n",
    "        raw = input[:, self.n_history - self.history_length:, :, :]\n",
    "        # smooth data\n",
    "        smoothed = []\n",
    "        for n_sm in range(2, self.n_smooth + 2):\n",
    "            smoothed.append(\n",
    "                tf.reduce_mean(tf.pack([input[:, self.n_history - st - self.history_length:self.n_history - st, :, :] for st in range(n_sm)]),0)\n",
    "            )\n",
    "        # downsample data\n",
    "        down = []\n",
    "        for n_dw in range(2, self.n_down + 2):\n",
    "            sampled_ = tf.pack([input[:, idx, :, :] for idx in range(self.n_history-n_dw*self.history_length, self.n_history, n_dw)])\n",
    "            down.append(tf.transpose(sampled_, [1, 0, 2, 3]))\n",
    "        return raw, smoothed, down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "n_stock = len(input_tilde.values[0])\n",
    "# n_stock = 99\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 10\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 100\n",
    "    n_feature = 32\n",
    "    update_rate = 1e-3\n",
    "    learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "# n_stock = len(input_tilde.values[0])\n",
    "n_stock = 10\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 6\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 10\n",
    "    n_feature = 5\n",
    "    update_rate = 1e-1\n",
    "    learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n",
      "finished building model!\n",
      "start!\n",
      "training....\n",
      "time: 2016-12-31 00:00:00\n",
      "loss: 0.524467\n",
      "elapsed time 1.9322500228881836\n",
      "time: 2017-01-01 00:00:00\n",
      "loss: 0.38431\n",
      "elapsed time 3.399729013442993\n",
      "time: 2017-01-02 00:00:00\n",
      "loss: 0.43145\n",
      "elapsed time 4.869863986968994\n",
      "time: 2017-01-03 00:00:00\n",
      "loss: 0.404334\n",
      "elapsed time 6.339478015899658\n",
      "time: 2017-01-04 00:00:00\n",
      "loss: 0.412303\n",
      "elapsed time 7.795673131942749\n",
      "time: 2017-01-05 00:00:00\n",
      "loss: 0.394469\n",
      "elapsed time 9.232843160629272\n",
      "time: 2017-01-06 00:00:00\n",
      "loss: 0.337144\n",
      "elapsed time 10.729063987731934\n",
      "time: 2017-01-07 00:00:00\n",
      "loss: 0.317811\n",
      "elapsed time 12.17319107055664\n",
      "time: 2017-01-08 00:00:00\n",
      "loss: 0.291078\n",
      "elapsed time 13.629656076431274\n",
      "time: 2017-01-09 00:00:00\n",
      "loss: 0.229183\n",
      "elapsed time 15.107736110687256\n",
      "time: 2017-01-10 00:00:00\n",
      "loss: 0.209092\n",
      "elapsed time 16.564615964889526\n",
      "time: 2017-01-11 00:00:00\n",
      "loss: 0.155955\n",
      "elapsed time 18.08369016647339\n",
      "time: 2017-01-12 00:00:00\n",
      "loss: 0.155972\n",
      "elapsed time 19.509696006774902\n",
      "time: 2017-01-13 00:00:00\n",
      "loss: 0.110087\n",
      "elapsed time 21.049232006072998\n",
      "time: 2017-01-14 00:00:00\n",
      "loss: 0.097565\n",
      "elapsed time 22.54629397392273\n",
      "time: 2017-01-15 00:00:00\n",
      "loss: 0.0834839\n",
      "elapsed time 23.997694969177246\n",
      "time: 2017-01-16 00:00:00\n",
      "loss: 0.0800365\n",
      "elapsed time 25.47820210456848\n",
      "time: 2017-01-17 00:00:00\n",
      "loss: 0.0644903\n",
      "elapsed time 26.977962017059326\n",
      "time: 2017-01-18 00:00:00\n",
      "loss: 0.0671217\n",
      "elapsed time 28.502073049545288\n",
      "time: 2017-01-19 00:00:00\n",
      "loss: 0.0684838\n",
      "elapsed time 30.03218698501587\n",
      "time: 2017-01-20 00:00:00\n",
      "loss: 0.0648668\n",
      "elapsed time 31.561828136444092\n",
      "time: 2017-01-21 00:00:00\n",
      "loss: 0.0736528\n",
      "elapsed time 33.092170000076294\n",
      "time: 2017-01-22 00:00:00\n",
      "loss: 0.0321635\n",
      "elapsed time 34.539478063583374\n",
      "time: 2017-01-23 00:00:00\n",
      "loss: 0.0388998\n",
      "elapsed time 36.07052803039551\n",
      "time: 2017-01-24 00:00:00\n",
      "loss: 0.0390139\n",
      "elapsed time 37.514342069625854\n",
      "time: 2017-01-25 00:00:00\n",
      "loss: 0.036229\n",
      "elapsed time 39.046364068984985\n",
      "time: 2017-01-26 00:00:00\n",
      "loss: 0.0355664\n",
      "elapsed time 40.53128409385681\n",
      "time: 2017-01-27 00:00:00\n",
      "loss: 0.0302089\n",
      "elapsed time 42.0080201625824\n",
      "time: 2017-01-28 00:00:00\n",
      "loss: 0.0311529\n",
      "elapsed time 43.51701498031616\n",
      "time: 2017-01-29 00:00:00\n",
      "loss: 0.0394013\n",
      "elapsed time 44.99341416358948\n",
      "time: 2017-01-30 00:00:00\n",
      "loss: 0.0338128\n",
      "elapsed time 46.54789900779724\n",
      "finished training\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# from model import DDPG\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = MultiDDPGConfig()\n",
    "\n",
    "dqn = DQN(config)\n",
    "print (\"start!\")\n",
    "values = dqn.train(input_data)\n",
    "print (\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13dff9fd0>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAECCAYAAAD0JMwBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSINSwIuINCgFvIhIg1LAi4g0qP8PYPzfp+5NUGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c7740f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(values[0].index, values[0].values)\n",
    "plt.plot(values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_label = input_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-04-01 00:00:00')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = list(date_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-04-01', '2015-04-02', '2015-04-06', '2015-04-07',\n",
       "               '2015-04-08', '2015-04-09', '2015-04-10', '2015-04-13',\n",
       "               '2015-04-14', '2015-04-15',\n",
       "               ...\n",
       "               '2016-03-18', '2016-03-21', '2016-03-22', '2016-03-23',\n",
       "               '2016-03-24', '2016-03-28', '2016-03-29', '2016-03-30',\n",
       "               '2016-03-31', '2016-04-01'],\n",
       "              dtype='datetime64[ns]', length=253, freq=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DatetimeIndex(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = [None] * 10\n",
    "dates = [None]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-23f7200d9f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "values[i].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros_141:0' shape=(2, 3, 4) dtype=int32>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2, 3, 4], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
