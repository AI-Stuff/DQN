{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_list = ['MMM', 'T', 'ABBV', 'ABT', 'ACN', 'AGN', 'ALL', 'GOOGL', \n",
    "              'GOOG', 'MO', 'AMZN', 'AXP', 'AIG', 'AMGN', 'AAPL', 'BAC', 'BIIB', \n",
    "              'BLK', 'BA', 'BMY', 'CVS', 'COF', 'CAT', 'CELG', 'CVX', 'CSCO', 'C', \n",
    "              'KO', 'CL', 'CMCSA', 'COP', 'COST', 'DHR', 'DOW', 'DUK', 'DD', 'EMC', \n",
    "              'EMR', 'EXC', 'XOM', 'FB', 'FDX', 'F', 'GD', 'GE', 'GM', 'GILD', 'GS', 'HAL', \n",
    "              'HD', 'HON', 'INTC', 'IBM', 'JPM', 'JNJ', 'KMI', 'LLY', 'LMT', 'LOW', 'MA', \n",
    "              'MCD', 'MDT', 'MRK', 'MET', 'MSFT', 'MDLZ', 'MON', 'MS', 'NKE', 'OXY', \n",
    "              'ORCL', 'PEP', 'PFE', 'PM', 'PG', 'QCOM', 'RTN', 'SLB', 'SPG', 'SO', 'SBUX', \n",
    "              'TGT', 'TXN', 'BK', 'PCLN', 'TWX', 'FOXA', 'FOX', 'USB', 'UNP', 'UPS', 'UTX', \n",
    "              'UNH', 'VZ', 'V', 'WMT', 'WBA', 'DIS', 'WFC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!!\n",
      "fail_name_list:  []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cdc8e6c48c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2014-04-01\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2016-04-01\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fixed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"time for getting data:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/work/github/DQN/utils.py\u001b[0m in \u001b[0;36mget_fixed_data\u001b[0;34m(name_list, start_date, end_date, data_type)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mdate_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datetime_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mstock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print (\"Started!!\")\n",
    "\n",
    "st = time.time()\n",
    "start_date=\"2014-04-01\"\n",
    "end_date=\"2016-04-01\"\n",
    "input_data, input_list = utils.get_fixed_data(input_list, start_date=start_date, end_date=end_date) \n",
    "elapsed = time.time() - st\n",
    "print (\"time for getting data:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_value = input_data.values\n",
    "index = input_data.index\n",
    "input_tilde = pd.DataFrame(input_value[:, :10], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (input_tilde.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(input_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG for trading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data, you are going to learn how to manage your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "# n_stock = len(input_tilde.values[0])\n",
    "n_stock = 10\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 6\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 10\n",
    "    n_feature = 5\n",
    "    update_rate = 1e-1\n",
    "    learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.date_range('23/10/2016', periods=100, freq='D')\n",
    "value = np.random.normal(0, 1, (len(index), n_stock))\n",
    "input_data = pd.DataFrame(value, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "import numpy as np\n",
    "\n",
    "Experiecne = namedtuple('Experience', 'state0, reward, state1')\n",
    "\n",
    "class RingBuffer(object):\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.start = 0\n",
    "        self.length = 0\n",
    "        # self.data = [None for _ in range(maxlen)]\n",
    "        self.data = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx< 0 or idx >= self.length:\n",
    "            raise KeyError()\n",
    "        return self.data[(self.start + idx) % self.maxlen]\n",
    "    \n",
    "    def append(self, v):\n",
    "        if self.length < self.maxlen:\n",
    "            # We have space, simply increase the length\n",
    "            self.length += 1\n",
    "        elif self.length == self.maxlen:\n",
    "            # No space, \"remove\" the first item\n",
    "            self.data[:-1] = self.data[1:]\n",
    "        else:\n",
    "            # This should never happen\n",
    "            raise RuntimeError()\n",
    "        self.data.append(v)\n",
    "        \n",
    "class SequentialMemory(object):\n",
    "    def __init__(self, limit=1000):\n",
    "        self.limit = limit\n",
    "        \n",
    "        self.rewards = RingBuffer(limit)\n",
    "        self.observations = RingBuffer(limit)\n",
    "        \n",
    "    def sample(self, batch_size, window_length):\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        batch_idx = np.random.random_integers(window_length, self.nb_entries - 1, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries - 1]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state0 = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        reward = np.array([self.rewards[idx - 1] for idx in batch_idx])\n",
    "        state1 = np.array([[self.observations[i] for i in range(idx - window_length + 1,idx + 1)] for idx in batch_idx])\n",
    "        return Experiecne(state0, reward, state1)\n",
    "    \n",
    "    def sample_state(self, batch_size, window_length):\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        batch_idx = np.random.random_integers(window_length, self.nb_entries - 1, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length, idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def append(self, observation, reward):\n",
    "        self.observations.append(observation)\n",
    "        self.rewards.append(reward)  \n",
    "    \n",
    "    @property\n",
    "    def nb_entries(self):\n",
    "        return  len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# from memory import SequentialMemory\n",
    "\n",
    "class DQN(object):\n",
    "    \"\"\"Deep Deterministic Poilicy Gradient\n",
    "    \n",
    "    Basend on DPG and Multiscale CNN, seek out \n",
    "    optimal strategy for stock trading.\n",
    "    \n",
    "    Available function\n",
    "    - build_model: build network basedon tensorflow and keras\n",
    "    - train: given DateFrame stock data, train network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        config should have the following attributes\n",
    "        \n",
    "        Args:\n",
    "            gamma(float): the decay rate for value at RL\n",
    "            history_length(int): input_length for each scale at CNN\n",
    "            n_feature(int): the number of type of input \n",
    "                (e.g. the number of company to use at stock trading)\n",
    "            trade_stock_idx(int): trading stock index\n",
    "            gam (float): discount factor\n",
    "            n_history(int): the nubmer of history that will be used as input\n",
    "            n_smooth, n_down(int): the number of smoothed and down sampling input at CNN\n",
    "            k_w(int): the size of filter at CNN\n",
    "            n_hidden(int): the size of fully connected layer\n",
    "            n_batch(int): the size of mini batch\n",
    "            n_epochs(int): the training epoch for each time\n",
    "            update_rate (0, 1): parameter for soft update\n",
    "            learning_rate(float): learning rate for SGD\n",
    "        \"\"\"\n",
    "        self.gamma = config.gamma\n",
    "        self.history_length = config.history_length\n",
    "        self.n_stock = config.n_stock\n",
    "        self.n_feature = config.n_feature\n",
    "        self.n_smooth = config.n_smooth\n",
    "        self.n_down = config.n_down\n",
    "        self.k_w = config.k_w\n",
    "        self.n_hidden = config.n_hidden\n",
    "        self.n_batch = config.n_batch\n",
    "        self.n_epochs = config.n_epochs\n",
    "        self.update_rate = config.update_rate\n",
    "        self.lr = config.learning_rate\n",
    "        # the actual dimention of input\n",
    "        self.n_input = (1 + self.n_smooth + self.n_down) * self.n_stock\n",
    "        # the length of the data as input\n",
    "        self.n_history = max(self.n_smooth + self.history_length , (self.n_down + 1) * self.history_length)\n",
    "        print (\"building model....\")\n",
    "        # have compatibility with new tensorflow\n",
    "        tf.python.control_flow_ops = tf\n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "        K.set_session(self.sess)\n",
    "        with self.sess.as_default():\n",
    "            self.build_model()\n",
    "        print('finished building model!')\n",
    "    \n",
    "    def train(self, input_data, noise_scale=2.0):\n",
    "        \"\"\"training DDPG, where action is confined to integer space\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): stock price for self.n_feature companies\n",
    "        \"\"\"\n",
    "        stock_data = input_data.values\n",
    "        date_data = input_data.index\n",
    "        T = len(stock_data)\n",
    "        \n",
    "        # frequency for output\n",
    "        print_freq = int(T / 100)\n",
    "        if print_freq == 0:\n",
    "            print_freq = 1\n",
    "            \n",
    "        print_freq = 1\n",
    "            \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        # the number of poassed stocks for each company\n",
    "        # result for return value\n",
    "        values = []\n",
    "        dates = []\n",
    "        for i in range(self.n_stock):\n",
    "            values.append([])\n",
    "            dates.append([])\n",
    "        # keep half an year data \n",
    "        memory = SequentialMemory(360)\n",
    "        for t in range(T):\n",
    "            price = stock_data[t]\n",
    "            reward = np.concatenate((np.reshape(stock_data[t], (self.n_stock, 1)), np.zeros((self.n_stock, 1))), axis=-1)\n",
    "            memory.append(price, reward)\n",
    "            # until having enough data, just do nothing\n",
    "            if t <= self.n_history + self.n_batch:\n",
    "                continue\n",
    "            # to stabilize batch normalization, use other samples for prediction\n",
    "            pred_state = memory.sample_state(self.n_batch, self.n_history)\n",
    "            # update network\n",
    "            action_value = self.sess.run(self.action,\n",
    "                                      feed_dict={self.state: pred_state,\n",
    "                                                K.learning_phase(): 0})[-1]\n",
    "            # add return value when exit value is better\n",
    "            for i in range(self.n_stock):\n",
    "                if action_value[i] == 0:\n",
    "                    values[i].append(price[i])\n",
    "                    dates[i].append(date_data[t])\n",
    "                    \n",
    "            for epoch in range(self.n_epochs):    \n",
    "                # select transition from pool\n",
    "                experiences = memory.sample(self.n_batch, self.n_history)\n",
    "                self.sess.run(self.critic_optim, \n",
    "                              feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.learning_rate: self.lr,\n",
    "                                         K.learning_phase(): 1})  \n",
    "                \n",
    "                loss = self.sess.run(self.loss, feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         K.learning_phase(): 0})\n",
    "                \n",
    "                \"\"\"\n",
    "                target_value = self.sess.run(self.target_value, feed_dict={\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         self.portfolio_target: experiences.portfolio1,\n",
    "                                         K.learning_phase(): 0})\n",
    "                \"\"\"\n",
    "                # print('critic_value', critic_value)\n",
    "                \n",
    "                \n",
    "                # print('target:', np.mean(target_value))\n",
    "                # print('Q_value:', np.mean(target_value - experiences.reward))\n",
    "                # print('reward:', np.mean(experiences.reward))\n",
    "                    \n",
    "                # softupdate for critic network\n",
    "                old_weights = self.critic_target.get_weights()\n",
    "                new_weights = self.critic.get_weights()\n",
    "                weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w for new_w, old_w in zip(new_weights, old_weights)]\n",
    "                self.critic_target.set_weights(weights)         \n",
    "                 \n",
    "            if t % print_freq == 0:\n",
    "                print (\"time:\",  date_data[t])\n",
    "                print('loss:', loss)\n",
    "                print (\"elapsed time\", time.time() - st)    \n",
    "\n",
    "        print (\"finished training\")\n",
    "           \n",
    "        return pd.DataFrame(values, index=pd.DatetimeIndex(date_label))\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build all of the network and optimizations\n",
    "        \n",
    "        just for conveninece of trainig, seprate placehoder for train and target network\n",
    "        critic network input: [raw_data, smoothed, downsampled, action]\n",
    "        actor network input: [raw_data, smoothed, downsampled]\n",
    "        \"\"\"\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic_target = self.build_critic()\n",
    "        # transform input into the several scales and smoothing\n",
    "        self.state =  tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state')\n",
    "        self.state_target = tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state_target')\n",
    "        # reshape to convolutional input\n",
    "        state_ = tf.reshape(self.state, [-1, self.n_history, self.n_stock, 1])\n",
    "        state_target_ = tf.reshape(self.state_target, [-1, self.n_history, self.n_stock, 1])\n",
    "        raw, smoothed, down = self.transform_input(state_)\n",
    "        raw_target, smoothed_target, down_target = self.transform_input(state_target_)\n",
    "        \n",
    "        # build graph for citic training\n",
    "        input_q = [raw,] +  smoothed + down\n",
    "        self.Q = self.critic(input_q)\n",
    "        self.action = tf.argmax(self.Q, dimension=2)\n",
    "        # target network\n",
    "        input_q_target = [raw_target,] +  smoothed_target + down_target\n",
    "        Q_target = self.critic_target(input_q_target)\n",
    "        self.reward = tf.placeholder(tf.float32, [None, self.n_stock, 2], name='reward')\n",
    "        Q_max =  tf.reshape(tf.reduce_max(Q_target, reduction_indices=[2]), [-1, self.n_stock, 1])\n",
    "        Q_value = tf.concat(2, (tf.zeros_like(Q_max), Q_max))\n",
    "        self.target = self.reward  + self.gamma * Q_value\n",
    "        # optimization\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        self.loss = tf.reduce_mean(tf.square(self.target - self.Q), name='loss')\n",
    "        self.critic_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(self.loss, var_list=self.critic.trainable_weights)\n",
    "        \n",
    "        # initialize network\n",
    "        tf.initialize_all_variables().run(session=self.sess)\n",
    "        weights = self.critic.get_weights()\n",
    "        self.critic_target.set_weights(weights)\n",
    "        \n",
    "    def build_critic(self):\n",
    "        \"\"\"Build critic network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        nf = self.n_feature\n",
    "        # layer1\n",
    "        # smoothed input\n",
    "        sm_model = [Sequential() for _ in range(self.n_smooth)]\n",
    "        for m in sm_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # down sampled input\n",
    "        dw_model = [Sequential() for _ in range(self.n_down)]\n",
    "        for m in dw_model:\n",
    "            m.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "            # m.add(SpatialDropout2D(0.2))\n",
    "            m.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "            m.add(BatchNormalization(mode=2, axis=-1))\n",
    "            m.add(PReLU())\n",
    "        # raw input\n",
    "        state = Sequential()\n",
    "        nf = self.n_feature\n",
    "        state.add(Lambda(lambda x: x,  input_shape=(self.history_length, self.n_stock, 1)))\n",
    "        # state.add(SpatialDropout2D(0.2))\n",
    "        state.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        state.add(BatchNormalization(mode=2, axis=-1))\n",
    "        state.add(PReLU())\n",
    "        merged = Merge([state,] + sm_model + dw_model, mode='concat', concat_axis=-1)\n",
    "        # layer2\n",
    "        nf = nf * 2\n",
    "        model = Sequential()\n",
    "        model.add(merged)\n",
    "        # merged_state.add(SpatialDropout2D(0.2))\n",
    "        model.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, border_mode='same'))\n",
    "        model.add(BatchNormalization(mode=2, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        model.add(Flatten())\n",
    "        # layer3\n",
    "        model.add(Dense(self.n_hidden))\n",
    "        model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # layer4\n",
    "        # model.add(Dropout(0.5))\n",
    "        model.add(Dense(int(np.sqrt(self.n_hidden))))\n",
    "        # model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        # output\n",
    "        # model.add(Dropout(0.5))\n",
    "        model.add(Dense(2 * self.n_stock))\n",
    "        model.add(Reshape((self.n_stock, 2)))\n",
    "        return model\n",
    "    \n",
    "    def transform_input(self, input):\n",
    "        # the last data is the newest information\n",
    "        raw = input[:, self.n_history - self.history_length:, :, :]\n",
    "        # smooth data\n",
    "        smoothed = []\n",
    "        for n_sm in range(2, self.n_smooth + 2):\n",
    "            smoothed.append(\n",
    "                tf.reduce_mean(tf.pack([input[:, self.n_history - st - self.history_length:self.n_history - st, :, :] for st in range(n_sm)]),0)\n",
    "            )\n",
    "        # downsample data\n",
    "        down = []\n",
    "        for n_dw in range(2, self.n_down + 2):\n",
    "            sampled_ = tf.pack([input[:, idx, :, :] for idx in range(self.n_history-n_dw*self.history_length, self.n_history, n_dw)])\n",
    "            down.append(tf.transpose(sampled_, [1, 0, 2, 3]))\n",
    "        return raw, smoothed, down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "n_stock = len(input_tilde.values[0])\n",
    "# n_stock = 99\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 10\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 100\n",
    "    n_feature = 32\n",
    "    update_rate = 1e-3\n",
    "    learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# input_data = np.zeros((505, 99))\n",
    "# n_stock = len(input_tilde.values[0])\n",
    "n_stock = 10\n",
    "\n",
    "class MultiDDPGConfig(object):\n",
    "    activation = 'relu'\n",
    "    gamma = 0.99\n",
    "    history_length = 6\n",
    "    n_stock = n_stock\n",
    "    n_smooth = 5\n",
    "    n_down = 5\n",
    "    k_w = 3\n",
    "    n_hidden = 100\n",
    "    n_batch = 32\n",
    "    n_epochs = 10\n",
    "    n_feature = 5\n",
    "    update_rate = 1e-1\n",
    "    learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n"
     ]
    }
   ],
   "source": [
    "# from model import DDPG\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "config = MultiDDPGConfig()\n",
    "\n",
    "dqn = DQN(config)\n",
    "print (\"start!\")\n",
    "values = dqn.train(input_data)\n",
    "print (\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdfa7cce310>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEDCAYAAADX1GjKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAxERAQlAxERQclARERQMhAREeD/A5Qfq3nQO2QcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdfa7b7f510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_label = input_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-04-01 00:00:00')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = list(date_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-04-01', '2015-04-02', '2015-04-06', '2015-04-07',\n",
       "               '2015-04-08', '2015-04-09', '2015-04-10', '2015-04-13',\n",
       "               '2015-04-14', '2015-04-15',\n",
       "               ...\n",
       "               '2016-03-18', '2016-03-21', '2016-03-22', '2016-03-23',\n",
       "               '2016-03-24', '2016-03-28', '2016-03-29', '2016-03-30',\n",
       "               '2016-03-31', '2016-04-01'],\n",
       "              dtype='datetime64[ns]', length=253, freq=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DatetimeIndex(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = [None] * 10\n",
    "dates = [None]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-23f7200d9f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "values[i].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros_141:0' shape=(2, 3, 4) dtype=int32>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2, 3, 4], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
